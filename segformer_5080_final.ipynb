{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2669e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# ğŸ”§ PYTORCH KURULUMU - RTX 5080 (sm_120) DESTEÄÄ° Ä°Ã‡Ä°N\n",
    "# ==============================================================================\n",
    "# RTX 5080 iÃ§in CUDA 12.8+ gereklidir (sm_120 desteÄŸi)\n",
    "# PyTorch'un en son sÃ¼rÃ¼mÃ¼ CUDA 12.8 ile kurulmalÄ±dÄ±r\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_pytorch():\n",
    "    \"\"\"PyTorch'u RTX 5080 iÃ§in CUDA 12.8 ile kurar\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ”§ PYTORCH KURULUMU - RTX 5080 Ä°Ã‡Ä°N\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ“¦ PyTorch + CUDA 12.8 kuruluyor (sm_120 desteÄŸi)...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Ã–nce mevcut sÃ¼rÃ¼mleri kaldÄ±r\n",
    "    try:\n",
    "        subprocess.check_call([\n",
    "            sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \n",
    "            \"torch\", \"torchvision\", \"torchaudio\"\n",
    "        ])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # CUDA 12.8 ile en son PyTorch sÃ¼rÃ¼mÃ¼nÃ¼ kur\n",
    "    subprocess.check_call([\n",
    "        sys.executable, \"-m\", \"pip\", \"install\",\n",
    "        \"torch\", \"torchvision\", \"torchaudio\",\n",
    "        \"--index-url\", \"https://download.pytorch.org/whl/cu128\"\n",
    "    ])\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"âœ… Kurulum tamamlandÄ±!\")\n",
    "    print(\"ğŸ”„ LÃ¼tfen kernel'Ä± restart edin (Kernel > Restart)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Kurulumu Ã§alÄ±ÅŸtÄ±r\n",
    "print(\"ğŸ”§ PyTorch kurulumu baÅŸlatÄ±lÄ±yor...\")\n",
    "install_pytorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0bee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import warnings\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# ==============================================================================\n",
    "# ğŸ”§ OPENMP Ã‡AKIÅMA Ã‡Ã–ZÃœMÃœ (Ã–nce bu ayarlanmalÄ±!)\n",
    "# ==============================================================================\n",
    "# OpenMP runtime Ã§akÄ±ÅŸmasÄ±nÄ± Ã¶nlemek iÃ§in\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "# NumPy threading ayarlarÄ±\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "# ==============================================================================\n",
    "# âš ï¸ PYTORCH IMPORT KONTROLÃœ - GELÄ°ÅMÄ°Å DLL HATASI Ã‡Ã–ZÃœMÃœ\n",
    "# ==============================================================================\n",
    "TORCH_AVAILABLE = False\n",
    "\n",
    "def diagnose_system():\n",
    "    \"\"\"Sistem durumunu teÅŸhis eder\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"ğŸ” SÄ°STEM TEÅHÄ°SÄ°\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Python bilgileri\n",
    "    print(f\"\\nğŸ“Œ Python: {sys.version}\")\n",
    "    print(f\"ğŸ“Œ Python Executable: {sys.executable}\")\n",
    "    print(f\"ğŸ“Œ Python Path: {sys.path[0]}\")\n",
    "    \n",
    "    # PyTorch kurulum kontrolÃ¼\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [sys.executable, \"-m\", \"pip\", \"show\", \"torch\"],\n",
    "            capture_output=True, text=True, timeout=10\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            lines = result.stdout.split('\\n')\n",
    "            for line in lines:\n",
    "                if 'Version:' in line:\n",
    "                    print(f\"ğŸ“¦ PyTorch Kurulu: {line.split(':')[1].strip()}\")\n",
    "                if 'Location:' in line:\n",
    "                    print(f\"ğŸ“ PyTorch Konumu: {line.split(':')[1].strip()}\")\n",
    "        else:\n",
    "            print(\"âŒ PyTorch kurulu deÄŸil veya eriÅŸilemiyor\")\n",
    "    except:\n",
    "        print(\"âš ï¸  PyTorch bilgisi alÄ±namadÄ±\")\n",
    "    \n",
    "    # Visual C++ Redistributables kontrolÃ¼ (Windows)\n",
    "    if sys.platform == 'win32':\n",
    "        try:\n",
    "            import winreg\n",
    "            vc_redist_found = False\n",
    "            try:\n",
    "                key = winreg.OpenKey(\n",
    "                    winreg.HKEY_LOCAL_MACHINE,\n",
    "                    r\"SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\"\n",
    "                )\n",
    "                for i in range(winreg.QueryInfoKey(key)[0]):\n",
    "                    try:\n",
    "                        subkey_name = winreg.EnumKey(key, i)\n",
    "                        subkey = winreg.OpenKey(key, subkey_name)\n",
    "                        try:\n",
    "                            display_name = winreg.QueryValueEx(subkey, \"DisplayName\")[0]\n",
    "                            if \"Visual C++\" in display_name and \"Redistributable\" in display_name:\n",
    "                                print(f\"âœ… {display_name}\")\n",
    "                                vc_redist_found = True\n",
    "                        except:\n",
    "                            pass\n",
    "                        subkey.Close()\n",
    "                    except:\n",
    "                        pass\n",
    "                key.Close()\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            if not vc_redist_found:\n",
    "                print(\"âŒ Visual C++ Redistributables BULUNAMADI!\")\n",
    "                print(\"   ğŸ”— Ä°ndir: https://aka.ms/vs/17/release/vc_redist.x64.exe\")\n",
    "        except:\n",
    "            print(\"âš ï¸  Visual C++ kontrolÃ¼ yapÄ±lamadÄ±\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "\n",
    "def deep_clean_pytorch():\n",
    "    \"\"\"PyTorch'u tamamen temizler\"\"\"\n",
    "    print(\"\\nğŸ§¹ PyTorch derin temizlik baÅŸlatÄ±lÄ±yor...\")\n",
    "    \n",
    "    # 1. Pip ile kaldÄ±r\n",
    "    try:\n",
    "        print(\"1ï¸âƒ£  Pip ile kaldÄ±rÄ±lÄ±yor...\")\n",
    "        subprocess.run(\n",
    "            [sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"torch\", \"torchvision\", \"torchaudio\"],\n",
    "            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, timeout=60\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # 2. Cache temizle\n",
    "    try:\n",
    "        print(\"2ï¸âƒ£  Pip cache temizleniyor...\")\n",
    "        subprocess.run(\n",
    "            [sys.executable, \"-m\", \"pip\", \"cache\", \"purge\"],\n",
    "            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, timeout=30\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # 3. Python cache temizle\n",
    "    try:\n",
    "        print(\"3ï¸âƒ£  Python cache temizleniyor...\")\n",
    "        site_packages = None\n",
    "        for path in sys.path:\n",
    "            if 'site-packages' in path:\n",
    "                site_packages = Path(path)\n",
    "                break\n",
    "        \n",
    "        if site_packages:\n",
    "            torch_dirs = ['torch', 'torchvision', 'torchaudio']\n",
    "            for dir_name in torch_dirs:\n",
    "                dir_path = site_packages / dir_name\n",
    "                if dir_path.exists():\n",
    "                    try:\n",
    "                        shutil.rmtree(dir_path)\n",
    "                        print(f\"   âœ… {dir_name} klasÃ¶rÃ¼ silindi\")\n",
    "                    except:\n",
    "                        pass\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # 4. __pycache__ temizle\n",
    "    try:\n",
    "        print(\"4ï¸âƒ£  __pycache__ temizleniyor...\")\n",
    "        for path in sys.path:\n",
    "            cache_path = Path(path) / '__pycache__'\n",
    "            if cache_path.exists():\n",
    "                try:\n",
    "                    shutil.rmtree(cache_path)\n",
    "                except:\n",
    "                    pass\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(\"âœ… Temizlik tamamlandÄ±!\")\n",
    "\n",
    "def reinstall_pytorch():\n",
    "    \"\"\"PyTorch'u RTX 5080 iÃ§in CUDA 12.8 ile yeniden kurar\"\"\"\n",
    "    print(\"\\nğŸ“¦ PyTorch yeniden kuruluyor (RTX 5080 iÃ§in CUDA 12.8)...\")\n",
    "    print(\"   Bu iÅŸlem 5-10 dakika sÃ¼rebilir...\")\n",
    "    \n",
    "    try:\n",
    "        # Conda varsa conda ile dene\n",
    "        conda_exe = shutil.which('conda')\n",
    "        if conda_exe:\n",
    "            print(\"   Conda ile kurulum deneniyor...\")\n",
    "            try:\n",
    "                subprocess.run([\n",
    "                    conda_exe, \"install\", \"-y\", \n",
    "                    \"pytorch\", \"torchvision\", \"torchaudio\", \n",
    "                    \"pytorch-cuda=12.8\", \n",
    "                    \"-c\", \"pytorch\", \"-c\", \"nvidia\"\n",
    "                ], timeout=600, check=True)\n",
    "                print(\"âœ… Conda ile kurulum baÅŸarÄ±lÄ±!\")\n",
    "                return True\n",
    "            except:\n",
    "                print(\"   Conda kurulumu baÅŸarÄ±sÄ±z, pip deneniyor...\")\n",
    "        \n",
    "        # Pip ile kur (CUDA 12.8 - RTX 5080 iÃ§in gerekli)\n",
    "        print(\"   Pip ile kurulum deneniyor (CUDA 12.8)...\")\n",
    "        subprocess.run([\n",
    "            sys.executable, \"-m\", \"pip\", \"install\",\n",
    "            \"torch\", \"torchvision\", \"torchaudio\",\n",
    "            \"--index-url\", \"https://download.pytorch.org/whl/cu128\",\n",
    "            \"--no-cache-dir\"\n",
    "        ], timeout=600, check=True)\n",
    "        print(\"âœ… Pip ile kurulum baÅŸarÄ±lÄ±!\")\n",
    "        return True\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"âŒ Kurulum zaman aÅŸÄ±mÄ±na uÄŸradÄ±\")\n",
    "        return False\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ Kurulum hatasÄ±: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Beklenmeyen hata: {e}\")\n",
    "        return False\n",
    "\n",
    "# ==============================================================================\n",
    "# ANA IMPORT DENEMESÄ°\n",
    "# ==============================================================================\n",
    "\n",
    "# RTX 5080 (sm_120) uyumluluk uyarÄ±sÄ±nÄ± filtrele\n",
    "warnings.filterwarnings('ignore', message='.*CUDA capability sm_120.*', category=UserWarning)\n",
    "\n",
    "# Ã–nce sistem teÅŸhisi yap\n",
    "diagnose_system()\n",
    "\n",
    "try:\n",
    "    # Circular import hatasÄ±nÄ± Ã¶nlemek iÃ§in cache temizle\n",
    "    if 'torch' in sys.modules:\n",
    "        del sys.modules['torch']\n",
    "        import importlib\n",
    "        importlib.invalidate_caches()\n",
    "    \n",
    "    import torch\n",
    "    TORCH_AVAILABLE = True\n",
    "    \n",
    "    # RTX 5080 uyumluluk kontrolÃ¼\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        cuda_capability = torch.cuda.get_device_capability(0)\n",
    "        cuda_major, cuda_minor = cuda_capability\n",
    "        \n",
    "        # sm_120 kontrolÃ¼ (12.0 = sm_120)\n",
    "        if cuda_major == 12 and cuda_minor == 0:\n",
    "            print(\"\\n\" + \"=\" * 70)\n",
    "            print(\"âš ï¸  RTX 5080 (sm_120) UYARISI\")\n",
    "            print(\"=\" * 70)\n",
    "            print(\"ğŸ“Œ GPU: RTX 5080 (CUDA Capability: 12.0)\")\n",
    "            print(\"ğŸ“Œ PyTorch CUDA Versiyonu:\", torch.version.cuda)\n",
    "            if torch.version.cuda and float(torch.version.cuda.split('.')[0] + '.' + torch.version.cuda.split('.')[1]) < 12.8:\n",
    "                print(\"âŒ PyTorch CUDA 12.8+ gereklidir!\")\n",
    "                print(\"ğŸ”§ Ã‡Ã¶zÃ¼m: CUDA 12.8 ile PyTorch kurun:\")\n",
    "                print(\"   pip uninstall -y torch torchvision torchaudio\")\n",
    "                print(\"   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\")\n",
    "            else:\n",
    "                print(\"âœ… CUDA 12.8+ kurulu - RTX 5080 destekleniyor!\")\n",
    "            print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"âœ… PYTORCH BAÅARIYLA YÃœKLENDÄ°!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"ğŸ“¦ Versiyon: {torch.__version__}\")\n",
    "    print(f\"ğŸ”§ OpenMP Ã‡akÄ±ÅŸma: Ã‡Ã¶zÃ¼ldÃ¼ (KMP_DUPLICATE_LIB_OK=TRUE)\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"ğŸ® CUDA: KullanÄ±labilir\")\n",
    "        print(f\"   CUDA Versiyon: {torch.version.cuda}\")\n",
    "        print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        cap = torch.cuda.get_device_capability(0)\n",
    "        print(f\"   CUDA Capability: {cap[0]}.{cap[1]} (sm_{cap[0]}{cap[1]})\")\n",
    "    else:\n",
    "        print(\"âš ï¸  CUDA: KullanÄ±lamÄ±yor (CPU modu)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "except (OSError, AttributeError, ImportError) as e:\n",
    "    error_msg = str(e)\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"âŒ PYTORCH YÃœKLENEMEDÄ°!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"ğŸ“‹ Hata: {error_msg}\")\n",
    "    \n",
    "    # DLL hatasÄ± kontrolÃ¼\n",
    "    if \"fbgemm.dll\" in error_msg or \"dll\" in error_msg.lower() or \"WinError 126\" in error_msg:\n",
    "        print(\"\\nğŸ” SORUN: DLL baÄŸÄ±mlÄ±lÄ±k hatasÄ±\")\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"ğŸ”§ Ã‡Ã–ZÃœM ADIMLARI (SÄ±rayla Deneyin)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        print(\"\\n1ï¸âƒ£  VISUAL C++ REDISTRIBUTABLES KURUN (ZORUNLU!)\")\n",
    "        print(\"   ğŸ”— Ä°ndir: https://aka.ms/vs/17/release/vc_redist.x64.exe\")\n",
    "        print(\"   âš ï¸  Kurulumdan sonra bilgisayarÄ± yeniden baÅŸlatÄ±n!\")\n",
    "        \n",
    "        print(\"\\n2ï¸âƒ£  DERÄ°N TEMÄ°ZLÄ°K VE YENÄ°DEN KURULUM\")\n",
    "        print(\"   AÅŸaÄŸÄ±daki kodu Ã§alÄ±ÅŸtÄ±rÄ±n:\")\n",
    "        print(\"   \" + \"-\" * 66)\n",
    "        print(\"   deep_clean_pytorch()\")\n",
    "        print(\"   reinstall_pytorch()\")\n",
    "        print(\"   \" + \"-\" * 66)\n",
    "        print(\"   Sonra kernel'Ä± restart edin ve tekrar deneyin.\")\n",
    "        \n",
    "        print(\"\\n3ï¸âƒ£  MANUEL TERMINAL KOMUTLARI (RTX 5080 iÃ§in CUDA 12.8)\")\n",
    "        print(\"   Terminal'de (conda activate seg5080 sonrasÄ±):\")\n",
    "        print(\"   \" + \"-\" * 66)\n",
    "        print(\"   pip uninstall -y torch torchvision torchaudio\")\n",
    "        print(\"   pip cache purge\")\n",
    "        print(\"   pip install torch torchvision torchaudio \\\\\")\n",
    "        print(\"       --index-url https://download.pytorch.org/whl/cu128 --no-cache-dir\")\n",
    "        print(\"   \" + \"-\" * 66)\n",
    "        print(\"   âš ï¸  Ã–NEMLÄ°: RTX 5080 iÃ§in CUDA 12.8 gereklidir (sm_120 desteÄŸi)\")\n",
    "        \n",
    "        print(\"\\n4ï¸âƒ£  ALTERNATÄ°F: CONDA Ä°LE KUR (BaÄŸÄ±mlÄ±lÄ±klarÄ± otomatik halleder)\")\n",
    "        print(\"   Terminal'de Ã§alÄ±ÅŸtÄ±rÄ±n:\")\n",
    "        print(\"   \" + \"-\" * 66)\n",
    "        print(\"   conda activate seg5080\")\n",
    "        print(\"   conda install pytorch torchvision torchaudio pytorch-cuda=12.8 \\\\\")\n",
    "        print(\"       -c pytorch -c nvidia\")\n",
    "        print(\"   \" + \"-\" * 66)\n",
    "        print(\"   âš ï¸  Ã–NEMLÄ°: RTX 5080 iÃ§in pytorch-cuda=12.8 gereklidir\")\n",
    "        \n",
    "        print(\"\\n5ï¸âƒ£  GEÃ‡Ä°CÄ° Ã‡Ã–ZÃœM: CPU-ONLY VERSÄ°YON (Test iÃ§in)\")\n",
    "        print(\"   EÄŸer Visual C++ kuramÄ±yorsanÄ±z, CPU-only ile test edebilirsiniz:\")\n",
    "        print(\"   \" + \"-\" * 66)\n",
    "        print(\"   pip uninstall -y torch torchvision torchaudio\")\n",
    "        print(\"   pip install torch torchvision torchaudio\")\n",
    "        print(\"   \" + \"-\" * 66)\n",
    "        print(\"   âš ï¸  Not: Bu versiyon GPU kullanmaz, sadece test iÃ§indir!\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"âš ï¸  Ã–NEMLÄ°: Visual C++ Redistributables olmadan Ã§alÄ±ÅŸmaz!\")\n",
    "        print(\"=\" * 70)\n",
    "        print(\"\\nğŸ“ ÅU ANDA YAPMANIZ GEREKENLER:\")\n",
    "        print(\"   1. Visual C++ Redistributables'Ä± kurun (yukarÄ±daki link)\")\n",
    "        print(\"   2. BilgisayarÄ± yeniden baÅŸlatÄ±n\")\n",
    "        print(\"   3. Bu cell'i tekrar Ã§alÄ±ÅŸtÄ±rÄ±n\")\n",
    "        print(\"=\" * 70)\n",
    "    \n",
    "    TORCH_AVAILABLE = False\n",
    "    # Hata mesajÄ±nÄ± gÃ¶ster ama execution'Ä± durdurma\n",
    "    raise\n",
    "\n",
    "# import torch_directml  <-- BUNU SÄ°L, ARTIK Ä°HTÄ°YACIN YOK\n",
    "\n",
    "# ==============================================================================\n",
    "# ğŸš€ RTX 5080 OPTÄ°MÄ°ZASYON AYARLARI (ArkadaÅŸÄ±nÄ±n dosyasÄ±ndan uyarlandÄ±)\n",
    "# ==============================================================================\n",
    "\n",
    "if TORCH_AVAILABLE:\n",
    "    # 1. Ortam DeÄŸiÅŸkenleri (DirectML ve KÄ±sÄ±tlamalarÄ± KaldÄ±rÄ±yoruz)\n",
    "    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\" \n",
    "    # CUDNN'i tekrar aÃ§Ä±yoruz (Senin dosyada kapalÄ±ydÄ±)\n",
    "    if \"TORCH_CUDNN_DISABLED\" in os.environ:\n",
    "        del os.environ[\"TORCH_CUDNN_DISABLED\"]\n",
    "\n",
    "    # 2. GPU HÄ±zlandÄ±rma AyarlarÄ±\n",
    "    torch.backends.cudnn.benchmark = True       # En hÄ±zlÄ± algoritmayÄ± seÃ§er\n",
    "    torch.backends.cudnn.deterministic = False  # HÄ±z iÃ§in deterministik modu kapa\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True # RTX 50 serisi iÃ§in TF32 aÃ§ (BÃ¼yÃ¼k HÄ±z ArtÄ±ÅŸÄ±!)\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "    # 3. Device TanÄ±mlama (DirectML yerine Native CUDA)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ğŸ® GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU âŒ'}\")\n",
    "    print(f\"ğŸ”§ CUDA SÃ¼rÃ¼mÃ¼: {torch.version.cuda}\")\n",
    "    print(f\"ğŸš€ Device: {device}\")\n",
    "    print(\"âš¡ TF32 HÄ±zlandÄ±rma: Aktif\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # RAM temizliÄŸi\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"âš ï¸  PyTorch yÃ¼klenemedi - YukarÄ±daki hata mesajÄ±na bakÄ±n\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ukzkhwyzggn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HUCRE 1.5: LOSS FUNCTIONS (DiceLoss, FocalLoss, DiceFocalLoss)\n",
    "# =============================================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Dice Loss for segmentation - directly optimizes IoU metric\n",
    "    Formula: 1 - (2 * intersection + smooth) / (pred + target + smooth)\n",
    "    \"\"\"\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: [B, C, H, W] logits\n",
    "            targets: [B, H, W] class indices\n",
    "        \"\"\"\n",
    "        num_classes = inputs.shape[1]\n",
    "        \n",
    "        # Softmax to get probabilities\n",
    "        inputs_soft = torch.softmax(inputs, dim=1)\n",
    "        \n",
    "        # One-hot encode targets\n",
    "        targets_one_hot = F.one_hot(targets.long(), num_classes=num_classes)\n",
    "        targets_one_hot = targets_one_hot.permute(0, 3, 1, 2).float()\n",
    "        \n",
    "        # Calculate Dice loss per class\n",
    "        dice_loss = 0.0\n",
    "        for c in range(num_classes):\n",
    "            pred_c = inputs_soft[:, c].contiguous().view(-1)\n",
    "            target_c = targets_one_hot[:, c].contiguous().view(-1)\n",
    "            \n",
    "            intersection = (pred_c * target_c).sum()\n",
    "            dice_score = (2. * intersection + self.smooth) / (\n",
    "                pred_c.sum() + target_c.sum() + self.smooth\n",
    "            )\n",
    "            dice_loss += (1 - dice_score)\n",
    "        \n",
    "        return dice_loss / num_classes\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss for addressing class imbalance in segmentation\n",
    "    Formula: FL(p_t) = -alpha_t * (1 - p_t)^gamma * log(p_t)\n",
    "    \n",
    "    Reference: https://arxiv.org/abs/1708.02002\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            alpha: Class weights tensor [weight_class0, weight_class1, ...]\n",
    "            gamma: Focusing parameter (higher = more focus on hard examples)\n",
    "            reduction: 'mean', 'sum', or 'none'\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: [B, C, H, W] logits\n",
    "            targets: [B, H, W] class indices\n",
    "        \"\"\"\n",
    "        # Flatten spatial dimensions\n",
    "        B, C, H, W = inputs.shape\n",
    "        inputs_flat = inputs.permute(0, 2, 3, 1).contiguous().view(-1, C)\n",
    "        targets_flat = targets.view(-1).long()\n",
    "        \n",
    "        # Cross entropy (without reduction)\n",
    "        ce_loss = F.cross_entropy(inputs_flat, targets_flat, reduction='none')\n",
    "        \n",
    "        # Get probability of correct class\n",
    "        p = torch.softmax(inputs_flat, dim=1)\n",
    "        p_t = p.gather(1, targets_flat.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        # Focal weight: (1 - p_t)^gamma\n",
    "        focal_weight = (1 - p_t) ** self.gamma\n",
    "        \n",
    "        # Apply focal weighting\n",
    "        focal_loss = focal_weight * ce_loss\n",
    "        \n",
    "        # Apply class weights if provided\n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha.to(inputs.device).gather(0, targets_flat)\n",
    "            focal_loss = alpha_t * focal_loss\n",
    "        \n",
    "        # Reduction\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "\n",
    "class DiceFocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Combined Dice + Focal Loss for segmentation\n",
    "    Best for: Binary segmentation with class imbalance\n",
    "    \n",
    "    Dice: Optimizes IoU directly (good for region overlap)\n",
    "    Focal: Handles class imbalance (focuses on hard examples)\n",
    "    \"\"\"\n",
    "    def __init__(self, dice_weight=0.6, focal_weight=0.4,\n",
    "                 focal_alpha=None, focal_gamma=2.0, smooth=1.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dice_weight: Weight for Dice loss (0-1)\n",
    "            focal_weight: Weight for Focal loss (0-1)\n",
    "            focal_alpha: Class weights for Focal loss\n",
    "            focal_gamma: Focusing parameter for Focal loss\n",
    "            smooth: Smoothing factor for Dice loss\n",
    "        \"\"\"\n",
    "        super(DiceFocalLoss, self).__init__()\n",
    "        self.dice_weight = dice_weight\n",
    "        self.focal_weight = focal_weight\n",
    "        self.dice_loss = DiceLoss(smooth=smooth)\n",
    "        self.focal_loss = FocalLoss(alpha=focal_alpha, gamma=focal_gamma)\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        dice = self.dice_loss(inputs, targets)\n",
    "        focal = self.focal_loss(inputs, targets)\n",
    "        combined = self.dice_weight * dice + self.focal_weight * focal\n",
    "        return combined\n",
    "\n",
    "\n",
    "print(\"Loss Functions tanimlandÄ±:\")\n",
    "print(\"  - DiceLoss: IoU optimizasyonu\")\n",
    "print(\"  - FocalLoss: Class imbalance icin\")\n",
    "print(\"  - DiceFocalLoss: Kombinasyon (Onerilen)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adedc5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HUCRE 2: AYARLAR (CONFIG) - GENISLETILMIS\n",
    "# =============================================================================\n",
    "from utils import create_training_folder\n",
    "\n",
    "# Notebook adÄ± (versiyonlama iÃ§in)\n",
    "NOTEBOOK_NAME = \"segformer_5080_final\"\n",
    "\n",
    "# Versiyonlu klasÃ¶r yapÄ±sÄ± oluÅŸtur\n",
    "base_dir, models_dir, data_dir, viz_dir, version = create_training_folder(NOTEBOOK_NAME)\n",
    "\n",
    "CONFIG = {\n",
    "    # =============================================\n",
    "    # 1. VERI AYARLARI\n",
    "    # =============================================\n",
    "    'root_dir': r\"C:\\AI_DATA\\SEMI_TRUTHS_extracted\", \n",
    "    #'csv_path': \"segmentation_dataset_balanced.csv\",  # Tek CSV dosyasÄ± (train/val/test iÃ§inde)\n",
    "    # VEYA ayrÄ± CSV dosyalarÄ± kullanÄ±lacaksa:\n",
    "    'train_csv_path': \"dataset_splits/fake_only_split/fake_train.csv\",\n",
    "    'val_csv_path': \"dataset_splits/fake_only_split/fake_val.csv\",\n",
    "    'test_csv_path': \"dataset_splits/fake_only_split/fake_test.csv\",\n",
    "    'dataset_name': \"SEMI_TRUTHS\",  # Dataset adÄ± (tracking iÃ§in)\n",
    "    \n",
    "    # Data Ratio: Ã–nceden belirlenmiÅŸ train/val/test CSV'lerinden ne kadarÄ±nÄ±n kullanÄ±lacaÄŸÄ±\n",
    "    'train_data_ratio': 0.01,  # Train CSV'den kullanÄ±lacak oran (0.0-1.0, 1.0 = tÃ¼mÃ¼)\n",
    "    'val_data_ratio': 0.01,    # Val CSV'den kullanÄ±lacak oran (0.0-1.0, 1.0 = tÃ¼mÃ¼)\n",
    "    'test_data_ratio': 0.01,   # Test CSV'den kullanÄ±lacak oran (0.0-1.0, 1.0 = tÃ¼mÃ¼, opsiyonel)\n",
    "    \n",
    "    # =============================================\n",
    "    # 2. MODEL AYARLARI\n",
    "    # =============================================\n",
    "    'model_name': \"nvidia/mit-b4\", \n",
    "    'model_variant': \"mit-b4\",  # Model variant (b0, b1, b2, b3, b4, b5)\n",
    "    'output_dir': models_dir,  # Versiyonlu klasÃ¶re kaydet\n",
    "    'img_size': 512,\n",
    "    'num_classes': 2,  # 0: Background, 1: Fake\n",
    "    \n",
    "    # =============================================\n",
    "    # 3. EGITIM HIPERPARAMETRELERI\n",
    "    # =============================================\n",
    "    'batch_size': 16,\n",
    "    'gradient_accumulation': 2,  # Effective batch = 16\n",
    "    'num_epochs': 10,\n",
    "    'learning_rate': 6e-5,\n",
    "    'weight_decay': 0.01,\n",
    "    'seed': 42,\n",
    "    \n",
    "    # =============================================\n",
    "    # 4. LOSS FUNCTION AYARLARI (YENÄ°!)\n",
    "    # =============================================\n",
    "    # Secenekler: 'crossentropy', 'focal', 'dice', 'dice_focal'\n",
    "    'loss_type': 'dice_focal',\n",
    "    \n",
    "    # Dice Loss ayarlarÄ±\n",
    "    'dice_weight': 0.6,        # Dice loss aÄŸÄ±rlÄ±ÄŸÄ± (0-1)\n",
    "    'dice_smooth': 1.0,        # Smoothing factor\n",
    "    \n",
    "    # Focal Loss ayarlarÄ±\n",
    "    'focal_weight': 0.4,       # Focal loss aÄŸÄ±rlÄ±ÄŸÄ± (0-1)\n",
    "    'focal_gamma': 2.0,        # Focusing parameter (2.0 standart)\n",
    "    'focal_alpha': [0.25, 0.75],  # Class weights [Background, Fake]\n",
    "    \n",
    "    # =============================================\n",
    "    # 5. CIKTI KLASORLERI (Versiyonlu)\n",
    "    # =============================================\n",
    "    'base_dir': base_dir,\n",
    "    'models_dir': models_dir,\n",
    "    'data_dir': data_dir,\n",
    "    'viz_dir': viz_dir,\n",
    "    'version': version,\n",
    "}\n",
    "\n",
    "# Seed sabitleme\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "np.random.seed(CONFIG['seed'])\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"EGITIM OTURUMU: {NOTEBOOK_NAME} - Version {version}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Model:     {CONFIG['model_name']}\")\n",
    "print(f\"  Loss:      {CONFIG['loss_type']}\")\n",
    "if CONFIG['loss_type'] == 'dice_focal':\n",
    "    print(f\"             Dice weight: {CONFIG['dice_weight']}, Focal weight: {CONFIG['focal_weight']}\")\n",
    "    print(f\"             Focal gamma: {CONFIG['focal_gamma']}, Alpha: {CONFIG['focal_alpha']}\")\n",
    "print(f\"  Batch:     {CONFIG['batch_size']} x {CONFIG['gradient_accumulation']} = {CONFIG['batch_size'] * CONFIG['gradient_accumulation']}\")\n",
    "print(f\"  Epochs:    {CONFIG['num_epochs']}\")\n",
    "print(f\"  LR:        {CONFIG['learning_rate']}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Models:    {models_dir}\")\n",
    "print(f\"  Data:      {data_dir}\")\n",
    "print(f\"  Viz:       {viz_dir}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1874628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HÃœCRE 3: Dataset SÄ±nÄ±fÄ± (TAMAMEN DÃœZELTÄ°LMÄ°Å)\n",
    "import os\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class FakeImageSegmentationDataset(Dataset):\n",
    "    def __init__(self, df, processor, is_train=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.processor = processor\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Gerekli kolonlarÄ± kontrol et\n",
    "        required_cols = ['image_path', 'mask_path']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(\n",
    "                f\"âŒ Dataset'te gerekli kolonlar eksik: {missing_cols}\\n\"\n",
    "                f\"   Mevcut kolonlar: {list(df.columns)}\\n\"\n",
    "                f\"   ğŸ’¡ Ã–nce mask_path kolonunu oluÅŸturun (HÃœCRE 4.5'teki kod Ã§alÄ±ÅŸtÄ±rÄ±lmalÄ±)\"\n",
    "            )\n",
    "        \n",
    "        # Metadata kolonlarÄ±nÄ± belirle (image_path ve mask_path hariÃ§)\n",
    "        metadata_cols = [col for col in df.columns \n",
    "                         if col not in ['image_path', 'mask_path']]\n",
    "        self.metadata_cols = metadata_cols\n",
    "        \n",
    "        # Augmentation (Veri Ã§eÅŸitlendirme - Sadece eÄŸitimde)\n",
    "        if is_train:\n",
    "            self.transform = A.Compose([\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.5),\n",
    "                A.OneOf([\n",
    "                    A.GridDistortion(p=0.3),\n",
    "                    A.ElasticTransform(p=0.3),\n",
    "                ], p=0.3),\n",
    "                A.RandomBrightnessContrast(p=0.3),\n",
    "            ], is_check_shapes=False)\n",
    "        else:\n",
    "            self.transform = None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def get_metadata(self, idx):\n",
    "        \"\"\"Get metadata for a given index\"\"\"\n",
    "        row = self.df.iloc[idx]\n",
    "        metadata = {}\n",
    "        for col in self.metadata_cols:\n",
    "            value = row.get(col, None)\n",
    "            # Convert numpy types to Python native types for JSON serialization\n",
    "            if isinstance(value, (np.integer, np.floating)):\n",
    "                metadata[col] = value.item()\n",
    "            elif isinstance(value, np.ndarray):\n",
    "                metadata[col] = value.tolist()\n",
    "            else:\n",
    "                metadata[col] = value\n",
    "        return metadata\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        try:\n",
    "            # GÃ¶rÃ¼ntÃ¼ (RGB)\n",
    "            image_path = row.get('image_path')\n",
    "            if pd.isna(image_path) or not os.path.exists(str(image_path)):\n",
    "                raise FileNotFoundError(f\"Image path bulunamadÄ± veya geÃ§ersiz: {image_path}\")\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            \n",
    "            # Maske (L - Grayscale)\n",
    "            mask_path = row.get('mask_path')\n",
    "            if pd.isna(mask_path) or mask_path is None:\n",
    "                raise ValueError(f\"mask_path eksik veya None (SatÄ±r {idx})\")\n",
    "            if not os.path.exists(str(mask_path)):\n",
    "                raise FileNotFoundError(f\"Mask dosyasÄ± bulunamadÄ±: {mask_path}\")\n",
    "            mask = Image.open(mask_path).convert(\"L\")\n",
    "            \n",
    "            # Boyut KontrolÃ¼\n",
    "            if image.size != mask.size:\n",
    "                mask = mask.resize(image.size, Image.NEAREST)\n",
    "            \n",
    "            image_np = np.array(image)\n",
    "            mask_np = np.array(mask)\n",
    "            \n",
    "            # ğŸ”¥ DÃœZELTÄ°LMÄ°Å MASKE MANTIÄI ğŸ”¥\n",
    "            # Simsiyah (0) olmayan her ÅŸeyi \"FAKE (1)\" yap.\n",
    "            mask_np = np.where(mask_np > 0, 1, 0).astype(np.uint8)\n",
    "            \n",
    "            # Augmentation\n",
    "            if self.transform and self.is_train:\n",
    "                augmented = self.transform(image=image_np, mask=mask_np)\n",
    "                image_np = augmented['image']\n",
    "                mask_np = augmented['mask']\n",
    "            \n",
    "            # Processor\n",
    "            encoded = self.processor(\n",
    "                images=image_np, \n",
    "                segmentation_maps=mask_np, \n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # Batch boyutunu sÄ±kÄ±ÅŸtÄ±r\n",
    "            for k, v in encoded.items():\n",
    "                encoded[k] = v.squeeze(0)\n",
    "            \n",
    "            # Metadata ekle (evaluation iÃ§in)\n",
    "            encoded['metadata'] = self.get_metadata(idx)\n",
    "            encoded['idx'] = idx\n",
    "                \n",
    "            return encoded\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Hata (SatÄ±r {idx}): {e}\")\n",
    "            # Hata durumunda bir sonraki veriyi dene\n",
    "            return self.__getitem__((idx + 1) % len(self.df))\n",
    "\n",
    "print(\"âœ… Dataset sÄ±nÄ±fÄ± tanÄ±mlandÄ± (TÃ¼m kÃ¼tÃ¼phanelerle birlikte).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HÃœCRE 4: Veri YÃ¼kleme ve HazÄ±rlÄ±k\n",
    "# Ã–nceden belirlenmiÅŸ train/val/test CSV'lerinden veri yÃ¼kleme\n",
    "\n",
    "# AyrÄ± CSV dosyalarÄ± var mÄ± kontrol et\n",
    "if 'train_csv_path' in CONFIG and 'val_csv_path' in CONFIG:\n",
    "    # AyrÄ± CSV dosyalarÄ± kullanÄ±lÄ±yor\n",
    "    print(\"=\"*60)\n",
    "    print(\"AYRI CSV DOSYALARINDAN VERÄ° YÃœKLEME\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Train CSV\n",
    "    if not os.path.exists(CONFIG['train_csv_path']):\n",
    "        raise FileNotFoundError(f\"âŒ Train CSV bulunamadÄ±: {CONFIG['train_csv_path']}\")\n",
    "    train_df_full = pd.read_csv(CONFIG['train_csv_path'])\n",
    "    print(f\"ğŸ“„ Train CSV: {len(train_df_full)} gÃ¶rsel\")\n",
    "    \n",
    "    # Val CSV\n",
    "    if not os.path.exists(CONFIG['val_csv_path']):\n",
    "        raise FileNotFoundError(f\"âŒ Val CSV bulunamadÄ±: {CONFIG['val_csv_path']}\")\n",
    "    val_df_full = pd.read_csv(CONFIG['val_csv_path'])\n",
    "    print(f\"ğŸ“„ Val CSV: {len(val_df_full)} gÃ¶rsel\")\n",
    "    \n",
    "    # Test CSV (opsiyonel)\n",
    "    test_df_full = None\n",
    "    if 'test_csv_path' in CONFIG and os.path.exists(CONFIG['test_csv_path']):\n",
    "        test_df_full = pd.read_csv(CONFIG['test_csv_path'])\n",
    "        print(f\"ğŸ“„ Test CSV: {len(test_df_full)} gÃ¶rsel\")\n",
    "    \n",
    "    # Data Ratio uygula\n",
    "    train_data_ratio = CONFIG.get('train_data_ratio', 1.0)\n",
    "    val_data_ratio = CONFIG.get('val_data_ratio', 1.0)\n",
    "    test_data_ratio = CONFIG.get('test_data_ratio', 1.0)\n",
    "    \n",
    "    if train_data_ratio < 1.0:\n",
    "        original_train = len(train_df_full)\n",
    "        train_df = train_df_full.sample(frac=train_data_ratio, random_state=CONFIG['seed']).reset_index(drop=True)\n",
    "        print(f\"ğŸ“Š Train Data Ratio: {train_data_ratio*100:.1f}% ({len(train_df)}/{original_train} gÃ¶rsel)\")\n",
    "    else:\n",
    "        train_df = train_df_full\n",
    "        print(f\"ğŸ“Š Train Data Ratio: {train_data_ratio*100:.1f}% (TÃ¼mÃ¼ kullanÄ±lÄ±yor)\")\n",
    "    \n",
    "    if val_data_ratio < 1.0:\n",
    "        original_val = len(val_df_full)\n",
    "        val_df = val_df_full.sample(frac=val_data_ratio, random_state=CONFIG['seed']).reset_index(drop=True)\n",
    "        print(f\"ğŸ“Š Val Data Ratio: {val_data_ratio*100:.1f}% ({len(val_df)}/{original_val} gÃ¶rsel)\")\n",
    "    else:\n",
    "        val_df = val_df_full\n",
    "        print(f\"ğŸ“Š Val Data Ratio: {val_data_ratio*100:.1f}% (TÃ¼mÃ¼ kullanÄ±lÄ±yor)\")\n",
    "    \n",
    "    if test_df_full is not None and test_data_ratio < 1.0:\n",
    "        original_test = len(test_df_full)\n",
    "        test_df = test_df_full.sample(frac=test_data_ratio, random_state=CONFIG['seed']).reset_index(drop=True)\n",
    "        print(f\"ğŸ“Š Test Data Ratio: {test_data_ratio*100:.1f}% ({len(test_df)}/{original_test} gÃ¶rsel)\")\n",
    "    elif test_df_full is not None:\n",
    "        test_df = test_df_full\n",
    "        print(f\"ğŸ“Š Test Data Ratio: {test_data_ratio*100:.1f}% (TÃ¼mÃ¼ kullanÄ±lÄ±yor)\")\n",
    "    \n",
    "else:\n",
    "    # Tek CSV dosyasÄ± kullanÄ±lÄ±yor (eski yÃ¶ntem - train/val split yapÄ±lacak)\n",
    "    print(\"=\"*60)\n",
    "    print(\"TEK CSV DOSYASINDAN VERÄ° YÃœKLEME (Train/Val Split)\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"âš ï¸  UYARI: AyrÄ± train/val/test CSV'leri kullanmak iÃ§in CONFIG'e train_csv_path ve val_csv_path ekleyin!\")\n",
    "    \n",
    "    if not os.path.exists(CONFIG['csv_path']):\n",
    "        raise FileNotFoundError(f\"âŒ CSV bulunamadÄ±: {CONFIG['csv_path']}\")\n",
    "    \n",
    "    df = pd.read_csv(CONFIG['csv_path'])\n",
    "    print(f\"ğŸ“„ Toplam Veri (CSV'den): {len(df)} gÃ¶rsel\")\n",
    "    \n",
    "    # Data Ratio uygula (train ve val iÃ§in aynÄ± oran)\n",
    "    train_data_ratio = CONFIG.get('train_data_ratio', 1.0)\n",
    "    val_data_ratio = CONFIG.get('val_data_ratio', 1.0)\n",
    "    \n",
    "    # Ã–nce data ratio uygula\n",
    "    if train_data_ratio < 1.0 or val_data_ratio < 1.0:\n",
    "        # Ortalama ratio kullan (veya train_data_ratio'yu kullan)\n",
    "        data_ratio = train_data_ratio if train_data_ratio < 1.0 else val_data_ratio\n",
    "        original_size = len(df)\n",
    "        df = df.sample(frac=data_ratio, random_state=CONFIG['seed']).reset_index(drop=True)\n",
    "        print(f\"ğŸ“Š Data Ratio UygulandÄ±: {data_ratio*100:.1f}% ({len(df)}/{original_size} gÃ¶rsel)\")\n",
    "    \n",
    "    # Train/Val Split (varsayÄ±lan %90/%10)\n",
    "    df_shuffled = df.sample(frac=1, random_state=CONFIG['seed']).reset_index(drop=True)\n",
    "    train_size = int(0.9 * len(df_shuffled))  # VarsayÄ±lan %90 train\n",
    "    \n",
    "    train_df = df_shuffled[:train_size]\n",
    "    val_df = df_shuffled[train_size:]\n",
    "    test_df = None\n",
    "\n",
    "# df'yi oluÅŸtur (tÃ¼m dataframes'i birleÅŸtir) - Cell 5 iÃ§in gerekli\n",
    "# EÄŸer df zaten varsa (tek CSV durumu), deÄŸiÅŸtirme\n",
    "try:\n",
    "    _ = df  # df var mÄ± kontrol et\n",
    "except NameError:\n",
    "    # df yok, ayrÄ± CSV'lerden yÃ¼klendi, birleÅŸtir\n",
    "    dfs_to_combine = [train_df, val_df]\n",
    "    if test_df is not None:\n",
    "        dfs_to_combine.append(test_df)\n",
    "    df = pd.concat(dfs_to_combine, ignore_index=True)\n",
    "    print(f\"ğŸ“‹ BirleÅŸtirilmiÅŸ DataFrame oluÅŸturuldu: {len(df)} satÄ±r\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VERÄ° SETÄ° Ã–ZETÄ°\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ“Š EÄŸitim Seti:    {len(train_df)} gÃ¶rsel\")\n",
    "print(f\"ğŸ§ª DoÄŸrulama Seti: {len(val_df)} gÃ¶rsel\")\n",
    "if test_df is not None:\n",
    "    print(f\"ğŸ§ª Test Seti:      {len(test_df)} gÃ¶rsel\")\n",
    "print(f\"ğŸ“ˆ Toplam KullanÄ±lan: {len(train_df) + len(val_df) + (len(test_df) if test_df is not None else 0)} gÃ¶rsel\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# =============================================================================\n",
    "# PATH KOLONLARINI OLUÅTUR (image_path ve mask_path)\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PATH KOLONLARINI OLUÅTURMA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Helper fonksiyon: DataFrame'e image_path ekle\n",
    "def add_image_path_column(dataframe, df_name=\"df\"):\n",
    "    \"\"\"DataFrame'e image_path kolonu ekler\"\"\"\n",
    "    if 'image_path' not in dataframe.columns:\n",
    "        if 'fake_img_path' in dataframe.columns:\n",
    "            dataframe['image_path'] = dataframe['fake_img_path']\n",
    "            print(f\"âœ… {df_name}: image_path oluÅŸturuldu (fake_img_path kullanÄ±ldÄ±)\")\n",
    "        elif 'img_path' in dataframe.columns:\n",
    "            dataframe['image_path'] = dataframe['img_path']\n",
    "            print(f\"âœ… {df_name}: image_path oluÅŸturuldu (img_path kullanÄ±ldÄ±)\")\n",
    "        else:\n",
    "            raise ValueError(f\"âŒ {df_name}: image_path oluÅŸturulamadÄ±! Mevcut kolonlar: {list(dataframe.columns)}\")\n",
    "    else:\n",
    "        print(f\"âœ… {df_name}: image_path zaten mevcut\")\n",
    "\n",
    "# 1. image_path kolonunu oluÅŸtur (df iÃ§in)\n",
    "add_image_path_column(df, \"df\")\n",
    "\n",
    "# train_df, val_df ve test_df'ye de image_path ekle\n",
    "if 'train_df' in locals():\n",
    "    add_image_path_column(train_df, \"train_df\")\n",
    "if 'val_df' in locals():\n",
    "    add_image_path_column(val_df, \"val_df\")\n",
    "if 'test_df' in locals() and test_df is not None:\n",
    "    add_image_path_column(test_df, \"test_df\")\n",
    "\n",
    "# 2. mask_path kolonunu oluÅŸtur (mask_id ve parent_dataset'ten)\n",
    "if 'mask_path' not in df.columns:\n",
    "    # Mask path oluÅŸturma fonksiyonu\n",
    "    def get_mask_path(mask_id, parent_dataset, root_dir=None):\n",
    "        \"\"\"\n",
    "        mask_id ve parent_dataset'ten mask path'i oluÅŸturur\n",
    "        \n",
    "        Args:\n",
    "            mask_id: Mask ID (Ã¶rn: 'instance_000_ADE_frame_00000004')\n",
    "            parent_dataset: Dataset adÄ± (Ã¶rn: 'ADE20K', 'CelebAHQ')\n",
    "            root_dir: Root directory (CONFIG['root_dir'] kullanÄ±lÄ±r)\n",
    "        \n",
    "        Returns:\n",
    "            str: Mask dosyasÄ±nÄ±n tam yolu veya None\n",
    "        \"\"\"\n",
    "        if pd.isna(mask_id) or pd.isna(parent_dataset):\n",
    "            return None\n",
    "        \n",
    "        if root_dir is None:\n",
    "            root_dir = CONFIG.get('root_dir', '')\n",
    "        \n",
    "        # Mask'ler genellikle {root_dir}/original/masks/{parent_dataset}_masks_{0,1,2}/ altÄ±nda\n",
    "        # Ã–nce masks klasÃ¶rÃ¼nÃ¼ bul\n",
    "        masks_base = os.path.join(root_dir, 'original', 'masks')\n",
    "        if not os.path.exists(masks_base):\n",
    "            # Alternatif: root_dir direkt masks iÃ§eriyor olabilir\n",
    "            masks_base = os.path.join(root_dir, 'masks')\n",
    "            if not os.path.exists(masks_base):\n",
    "                masks_base = root_dir  # Son Ã§are: root_dir direkt\n",
    "        \n",
    "        # Her dataset iÃ§in 3 klasÃ¶r var (_0, _1, _2)\n",
    "        possible_folders = [\n",
    "            os.path.join(masks_base, f\"{parent_dataset}_masks_0\"),\n",
    "            os.path.join(masks_base, f\"{parent_dataset}_masks_1\"),\n",
    "            os.path.join(masks_base, f\"{parent_dataset}_masks_2\")\n",
    "        ]\n",
    "        \n",
    "        # Her klasÃ¶rde mask'i ara\n",
    "        for folder in possible_folders:\n",
    "            mask_path = os.path.join(folder, f\"{mask_id}.png\")\n",
    "            if os.path.exists(mask_path):\n",
    "                return mask_path\n",
    "        \n",
    "        # Bulunamazsa None dÃ¶ndÃ¼r\n",
    "        return None\n",
    "    \n",
    "    # mask_id ve parent_dataset kolonlarÄ±nÄ± kontrol et\n",
    "    if 'mask_id' not in df.columns:\n",
    "        raise ValueError(f\"âŒ mask_id kolonu bulunamadÄ±! Mevcut kolonlar: {list(df.columns)}\")\n",
    "    \n",
    "    if 'parent_dataset' not in df.columns:\n",
    "        # Alternatif: 'dataset' kolonu olabilir\n",
    "        if 'dataset' in df.columns:\n",
    "            df['parent_dataset'] = df['dataset']\n",
    "            print(\"âœ… parent_dataset oluÅŸturuldu: dataset kolonu kullanÄ±ldÄ±\")\n",
    "        else:\n",
    "            raise ValueError(f\"âŒ parent_dataset veya dataset kolonu bulunamadÄ±! Mevcut kolonlar: {list(df.columns)}\")\n",
    "    \n",
    "    # mask_path'leri oluÅŸtur\n",
    "    print(\"ğŸ”„ mask_path kolonlarÄ± oluÅŸturuluyor...\")\n",
    "    root_dir = CONFIG.get('root_dir', '')\n",
    "    print(f\"   Root dir: {root_dir}\")\n",
    "    \n",
    "    # Ä°lk birkaÃ§ Ã¶rnek iÃ§in debug bilgisi\n",
    "    if len(df) > 0:\n",
    "        sample_row = df.iloc[0]\n",
    "        sample_mask_id = sample_row.get('mask_id')\n",
    "        sample_parent_dataset = sample_row.get('parent_dataset')\n",
    "        print(f\"   Ã–rnek mask_id: {sample_mask_id}\")\n",
    "        print(f\"   Ã–rnek parent_dataset: {sample_parent_dataset}\")\n",
    "        \n",
    "        # Mask base path'leri kontrol et\n",
    "        masks_base_options = [\n",
    "            os.path.join(root_dir, 'original', 'masks'),\n",
    "            os.path.join(root_dir, 'masks'),\n",
    "            root_dir\n",
    "        ]\n",
    "        for masks_base in masks_base_options:\n",
    "            if os.path.exists(masks_base):\n",
    "                print(f\"   âœ… Masks base bulundu: {masks_base}\")\n",
    "                # Ä°lk dataset klasÃ¶rÃ¼nÃ¼ kontrol et\n",
    "                if sample_parent_dataset:\n",
    "                    sample_folder = os.path.join(masks_base, f\"{sample_parent_dataset}_masks_0\")\n",
    "                    if os.path.exists(sample_folder):\n",
    "                        print(f\"   âœ… Ã–rnek klasÃ¶r bulundu: {sample_folder}\")\n",
    "                    else:\n",
    "                        print(f\"   âš ï¸  Ã–rnek klasÃ¶r bulunamadÄ±: {sample_folder}\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"   âš ï¸  HiÃ§bir masks base bulunamadÄ±!\")\n",
    "    \n",
    "    mask_paths = []\n",
    "    missing_count = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        mask_id = row.get('mask_id')\n",
    "        parent_dataset = row.get('parent_dataset')\n",
    "        mask_path = get_mask_path(mask_id, parent_dataset, root_dir)\n",
    "        \n",
    "        if mask_path is None:\n",
    "            missing_count += 1\n",
    "            mask_paths.append(None)\n",
    "        else:\n",
    "            mask_paths.append(mask_path)\n",
    "    \n",
    "    df['mask_path'] = mask_paths\n",
    "    \n",
    "    if missing_count > 0:\n",
    "        print(f\"âš ï¸  {missing_count} mask path bulunamadÄ± ({missing_count/len(df)*100:.2f}%)\")\n",
    "        if missing_count == len(df):\n",
    "            print(f\"   âš ï¸  TÃœM MASK PATH'LER BULUNADI! Root dir veya mask yapÄ±sÄ± yanlÄ±ÅŸ olabilir.\")\n",
    "            print(f\"   ğŸ’¡ CONFIG['root_dir'] deÄŸerini kontrol edin: {root_dir}\")\n",
    "        # Eksik mask'leri temizle\n",
    "        df = df.dropna(subset=['mask_path']).reset_index(drop=True)\n",
    "        print(f\"ğŸ§¹ Eksik mask'ler temizlendi: {len(df)} satÄ±r kaldÄ±\")\n",
    "    else:\n",
    "        print(f\"âœ… TÃ¼m mask path'ler baÅŸarÄ±yla oluÅŸturuldu\")\n",
    "    \n",
    "    # train_df, val_df ve test_df'ye de mask_path ekle\n",
    "    # AyrÄ± CSV'lerden yÃ¼klendiÄŸinde bunlara da eklememiz gerekiyor\n",
    "    dataframes_to_update = []\n",
    "    if 'train_df' in locals():\n",
    "        dataframes_to_update.append(('train_df', train_df))\n",
    "    if 'val_df' in locals():\n",
    "        dataframes_to_update.append(('val_df', val_df))\n",
    "    if 'test_df' in locals() and test_df is not None:\n",
    "        dataframes_to_update.append(('test_df', test_df))\n",
    "    \n",
    "    # Her DataFrame iÃ§in mask_path ekle\n",
    "    for df_name, df_to_update in dataframes_to_update:\n",
    "        # mask_path kolonu yoksa veya Ã§oÄŸu deÄŸer None/boÅŸsa yeniden oluÅŸtur\n",
    "        needs_mask_path = False\n",
    "        if 'mask_path' not in df_to_update.columns:\n",
    "            needs_mask_path = True\n",
    "        else:\n",
    "            # mask_path kolonu varsa ama Ã§oÄŸu deÄŸer None/boÅŸsa yeniden oluÅŸtur\n",
    "            valid_mask_paths = df_to_update['mask_path'].notna() & (df_to_update['mask_path'] != '')\n",
    "            valid_count = valid_mask_paths.sum()\n",
    "            if valid_count < len(df_to_update) * 0.5:  # %50'den az geÃ§erli ise\n",
    "                print(f\"   âš ï¸  {df_name}: mask_path kolonu var ama Ã§oÄŸu deÄŸer eksik ({valid_count}/{len(df_to_update)}), yeniden oluÅŸturuluyor...\")\n",
    "                needs_mask_path = True\n",
    "        \n",
    "        if needs_mask_path:\n",
    "            print(f\"ğŸ”„ {df_name} iÃ§in mask_path ekleniyor...\")\n",
    "            \n",
    "            # mask_id kontrolÃ¼\n",
    "            if 'mask_id' not in df_to_update.columns:\n",
    "                raise ValueError(f\"âŒ {df_name}: mask_id kolonu bulunamadÄ±! Mevcut kolonlar: {list(df_to_update.columns)}\")\n",
    "            \n",
    "            # parent_dataset kontrolÃ¼\n",
    "            if 'parent_dataset' not in df_to_update.columns:\n",
    "                if 'dataset' in df_to_update.columns:\n",
    "                    df_to_update['parent_dataset'] = df_to_update['dataset']\n",
    "                    print(f\"   âœ… {df_name}: parent_dataset oluÅŸturuldu (dataset kolonu kullanÄ±ldÄ±)\")\n",
    "                else:\n",
    "                    raise ValueError(f\"âŒ {df_name}: parent_dataset veya dataset kolonu bulunamadÄ±! Mevcut kolonlar: {list(df_to_update.columns)}\")\n",
    "            \n",
    "            mask_paths_sub = []\n",
    "            missing_count_sub = 0\n",
    "            for idx, row in df_to_update.iterrows():\n",
    "                mask_id = row.get('mask_id')\n",
    "                parent_dataset = row.get('parent_dataset')\n",
    "                \n",
    "                # mask_id veya parent_dataset eksikse None ekle\n",
    "                if pd.isna(mask_id) or pd.isna(parent_dataset):\n",
    "                    missing_count_sub += 1\n",
    "                    mask_paths_sub.append(None)\n",
    "                else:\n",
    "                    mask_path = get_mask_path(mask_id, parent_dataset, root_dir)\n",
    "                    if mask_path is None:\n",
    "                        missing_count_sub += 1\n",
    "                        mask_paths_sub.append(None)\n",
    "                    else:\n",
    "                        mask_paths_sub.append(mask_path)\n",
    "            \n",
    "            df_to_update['mask_path'] = mask_paths_sub\n",
    "            \n",
    "            if missing_count_sub > 0:\n",
    "                print(f\"   âš ï¸  {df_name}: {missing_count_sub} mask path bulunamadÄ± ({missing_count_sub/len(df_to_update)*100:.2f}%)\")\n",
    "                # Eksik mask'leri temizle\n",
    "                df_to_update.dropna(subset=['mask_path'], inplace=True)\n",
    "                df_to_update.reset_index(drop=True, inplace=True)\n",
    "                print(f\"   ğŸ§¹ {df_name}: Eksik mask'ler temizlendi, {len(df_to_update)} satÄ±r kaldÄ±\")\n",
    "            else:\n",
    "                print(f\"   âœ… {df_name}: TÃ¼m mask path'ler baÅŸarÄ±yla oluÅŸturuldu\")\n",
    "        else:\n",
    "            # mask_path zaten mevcut ve geÃ§erli\n",
    "            valid_count = (df_to_update['mask_path'].notna() & (df_to_update['mask_path'] != '')).sum()\n",
    "            print(f\"   âœ… {df_name}: mask_path zaten mevcut ({valid_count}/{len(df_to_update)} geÃ§erli)\")\n",
    "    \n",
    "    # EÄŸer tek CSV'den split edildiyse, yeniden split yap\n",
    "    if len(dataframes_to_update) == 0 and 'train_df' in locals() and 'val_df' in locals():\n",
    "        # df'den mask_path eklenmiÅŸ, train/val split'i yeniden yap\n",
    "        if len(df) > 0:\n",
    "            train_size = int(0.9 * len(df))  # VarsayÄ±lan %90 train\n",
    "            df_shuffled = df.sample(frac=1, random_state=CONFIG['seed']).reset_index(drop=True)\n",
    "            train_df = df_shuffled[:train_size]\n",
    "            val_df = df_shuffled[train_size:]\n",
    "            print(f\"ğŸ”„ train_df ve val_df mask_path ile gÃ¼ncellendi\")\n",
    "    \n",
    "    print(\"âœ… mask_path kolonu oluÅŸturuldu\")\n",
    "else:\n",
    "    print(\"âœ… mask_path zaten mevcut\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HÃœCRE 4.5: CSV VALÄ°DASYON KONTROLÃœ (GeliÅŸtirilmiÅŸ)\n",
    "# =============================================================================\n",
    "# Bu hÃ¼cre, CSV'nin doÄŸru yÃ¼klendiÄŸini ve kullanÄ±ldÄ±ÄŸÄ±nÄ± kontrol eder\n",
    "# HÃœCRE 4'ten sonra Ã§alÄ±ÅŸtÄ±rÄ±n\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CSV VALÄ°DASYON KONTROLÃœ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. DataFrame'in varlÄ±ÄŸÄ±nÄ± kontrol et\n",
    "if 'df' not in locals() or df is None:\n",
    "    raise ValueError(\"âŒ DataFrame 'df' bulunamadÄ±! Ã–nce HÃœCRE 4'Ã¼ Ã§alÄ±ÅŸtÄ±rÄ±n.\")\n",
    "\n",
    "# 2. Gerekli kolonlarÄ± kontrol et\n",
    "required_cols = ['image_path', 'mask_path']\n",
    "missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"âŒ EKSÄ°K KOLONLAR: {missing_cols}\")\n",
    "    print(f\"   Mevcut kolonlar: {list(df.columns)}\")\n",
    "    raise ValueError(f\"CSV'de gerekli kolonlar eksik: {missing_cols}\")\n",
    "else:\n",
    "    print(f\"âœ… Gerekli kolonlar mevcut: {required_cols}\")\n",
    "\n",
    "# 3. BoÅŸ deÄŸer kontrolÃ¼\n",
    "print(f\"\\nğŸ“Š BoÅŸ DeÄŸer Analizi:\")\n",
    "has_nulls = False\n",
    "for col in required_cols:\n",
    "    null_count = df[col].isnull().sum()\n",
    "    if null_count > 0:\n",
    "        print(f\"  âš ï¸  {col}: {null_count} boÅŸ deÄŸer ({null_count/len(df)*100:.2f}%)\")\n",
    "        has_nulls = True\n",
    "    else:\n",
    "        print(f\"  âœ… {col}: BoÅŸ deÄŸer yok\")\n",
    "\n",
    "# 4. Train/Val DataFrame'lerini kontrol et\n",
    "if 'train_df' not in locals() or 'val_df' not in locals():\n",
    "    print(\"\\nâš ï¸  train_df veya val_df bulunamadÄ±!\")\n",
    "else:\n",
    "    print(f\"\\nğŸ“Š Train/Val Split KontrolÃ¼:\")\n",
    "    print(f\"  âœ… Train: {len(train_df)} satÄ±r\")\n",
    "    print(f\"  âœ… Val:   {len(val_df)} satÄ±r\")\n",
    "    print(f\"  âœ… Toplam: {len(train_df) + len(val_df)} satÄ±r\")\n",
    "    \n",
    "    # Train/Val'de gerekli kolonlar var mÄ±?\n",
    "    for col in required_cols:\n",
    "        if col not in train_df.columns or col not in val_df.columns:\n",
    "            print(f\"  âŒ {col} train_df veya val_df'de eksik!\")\n",
    "        else:\n",
    "            print(f\"  âœ… {col} her iki DataFrame'de mevcut\")\n",
    "\n",
    "# 5. Path geÃ§erliliÄŸi Ã¶rnek kontrolÃ¼ (ilk 5 satÄ±r)\n",
    "print(f\"\\nğŸ” Path GeÃ§erliliÄŸi Ã–rnek KontrolÃ¼ (ilk 5 satÄ±r):\")\n",
    "if len(df) == 0:\n",
    "    print(\"  âš ï¸  DataFrame boÅŸ! Path kontrolÃ¼ yapÄ±lamÄ±yor.\")\n",
    "else:\n",
    "    sample_size = min(5, len(df))\n",
    "    valid_count = 0\n",
    "    for idx in range(sample_size):\n",
    "        img_path = df.iloc[idx]['image_path']\n",
    "        mask_path = df.iloc[idx]['mask_path']\n",
    "        \n",
    "        img_exists = os.path.exists(str(img_path)) if pd.notna(img_path) else False\n",
    "        mask_exists = os.path.exists(str(mask_path)) if pd.notna(mask_path) else False\n",
    "        \n",
    "        if img_exists and mask_exists:\n",
    "            valid_count += 1\n",
    "            print(f\"  âœ… SatÄ±r {idx}: Her iki path geÃ§erli\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸  SatÄ±r {idx}:\")\n",
    "            print(f\"     Image: {'âœ…' if img_exists else 'âŒ'} {str(img_path)[:80] if pd.notna(img_path) else 'None'}\")\n",
    "            print(f\"     Mask:  {'âœ…' if mask_exists else 'âŒ'} {str(mask_path)[:80] if pd.notna(mask_path) else 'None'}\")\n",
    "    \n",
    "    if sample_size > 0:\n",
    "        print(f\"\\nğŸ“ˆ Ã–rnek GeÃ§erlilik OranÄ±: {valid_count}/{sample_size} ({valid_count/sample_size*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"  âš ï¸  Ã–rnek kontrol yapÄ±lamadÄ± (DataFrame boÅŸ)\")\n",
    "\n",
    "# 6. Metadata kolonlarÄ±\n",
    "metadata_cols = [col for col in df.columns if col not in required_cols]\n",
    "print(f\"\\nğŸ“‹ Metadata KolonlarÄ±: {len(metadata_cols)} adet\")\n",
    "if metadata_cols:\n",
    "    print(f\"   Ä°lk 10: {', '.join(metadata_cols[:10])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… CSV VALÄ°DASYON TAMAMLANDI\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6446e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HÃœCRE 5: Model ve Processor Ä°ndirme\n",
    "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
    "print(\"ğŸ”„ Model ve Processor indiriliyor (mit-b4)...\")\n",
    "\n",
    "# Processor\n",
    "processor = SegformerImageProcessor.from_pretrained(\n",
    "    CONFIG['model_name'], \n",
    "    do_reduce_labels=False,\n",
    "    size={\"height\": CONFIG['img_size'], \"width\": CONFIG['img_size']}\n",
    ")\n",
    "\n",
    "# Model\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    CONFIG['model_name'],\n",
    "    num_labels=CONFIG['num_classes'],\n",
    "    id2label={0: \"Background\", 1: \"Fake\"},\n",
    "    label2id={\"Background\": 0, \"Fake\": 1},\n",
    "    ignore_mismatched_sizes=True,\n",
    "    #use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "print(\"âœ… Model baÅŸarÄ±yla yÃ¼klendi ve GPU'ya taÅŸÄ±ndÄ±.\")\n",
    "\n",
    "# Dataset Objelerini OluÅŸtur\n",
    "train_dataset = FakeImageSegmentationDataset(train_df, processor, is_train=True)\n",
    "val_dataset = FakeImageSegmentationDataset(val_df, processor, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8537fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HUCRE 6: ENHANCED METRICS (Confidence Tracking ile)\n",
    "# =============================================================================\n",
    "import evaluate\n",
    "from scipy import ndimage\n",
    "\n",
    "def compute_metrics_with_confidence(eval_pred):\n",
    "    \"\"\"\n",
    "    Enhanced metrics including:\n",
    "    - Standard IoU metrics (mean_iou, fake_iou, bg_iou)\n",
    "    - Confidence metrics (per-pixel, boundary, sample-level)\n",
    "    - Boundary analysis (edge vs interior IoU)\n",
    "    \"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    # Convert to tensors\n",
    "    logits_tensor = torch.from_numpy(logits)\n",
    "    \n",
    "    # Upsample logits to match label size\n",
    "    logits_upsampled = torch.nn.functional.interpolate(\n",
    "        logits_tensor, size=labels.shape[-2:],\n",
    "        mode=\"bilinear\", align_corners=False\n",
    "    )\n",
    "    \n",
    "    # Get predictions and probabilities\n",
    "    probs = torch.softmax(logits_upsampled, dim=1)\n",
    "    preds = probs.argmax(dim=1).numpy()\n",
    "    probs_np = probs.numpy()\n",
    "    \n",
    "    # === STANDARD IoU METRICS ===\n",
    "    metric = evaluate.load(\"mean_iou\")\n",
    "    iou_metrics = metric.compute(\n",
    "        predictions=preds,\n",
    "        references=labels,\n",
    "        num_labels=CONFIG['num_classes'],\n",
    "        ignore_index=255,\n",
    "        reduce_labels=False\n",
    "    )\n",
    "    \n",
    "    # === CONFIDENCE METRICS ===\n",
    "    valid_mask = labels != 255\n",
    "    \n",
    "    # 1. Per-pixel average confidence (mean of max softmax)\n",
    "    max_probs = probs_np.max(axis=1)  # [B, H, W]\n",
    "    avg_pixel_confidence = float(max_probs[valid_mask].mean()) if valid_mask.sum() > 0 else 0.0\n",
    "    \n",
    "    # 2. Boundary confidence (edge pixels only using sobel)\n",
    "    boundary_confidences = []\n",
    "    boundary_ious = []\n",
    "    interior_ious = []\n",
    "    sample_ious = []\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        # Detect edges using sobel on ground truth\n",
    "        edges = np.abs(ndimage.sobel(labels[i].astype(float), axis=0)) + \\\n",
    "                np.abs(ndimage.sobel(labels[i].astype(float), axis=1))\n",
    "        edge_mask = (edges > 0) & valid_mask[i]\n",
    "        interior_mask = (edges == 0) & valid_mask[i]\n",
    "        \n",
    "        # Boundary confidence\n",
    "        if edge_mask.sum() > 0:\n",
    "            boundary_conf = max_probs[i][edge_mask].mean()\n",
    "            boundary_confidences.append(float(boundary_conf))\n",
    "            \n",
    "            # Boundary IoU (Fake class only)\n",
    "            pred_edge = preds[i][edge_mask]\n",
    "            label_edge = labels[i][edge_mask]\n",
    "            intersection = ((pred_edge == 1) & (label_edge == 1)).sum()\n",
    "            union = ((pred_edge == 1) | (label_edge == 1)).sum()\n",
    "            if union > 0:\n",
    "                boundary_ious.append(float(intersection / union))\n",
    "        \n",
    "        # Interior IoU\n",
    "        if interior_mask.sum() > 0:\n",
    "            pred_int = preds[i][interior_mask]\n",
    "            label_int = labels[i][interior_mask]\n",
    "            intersection = ((pred_int == 1) & (label_int == 1)).sum()\n",
    "            union = ((pred_int == 1) | (label_int == 1)).sum()\n",
    "            if union > 0:\n",
    "                interior_ious.append(float(intersection / union))\n",
    "        \n",
    "        # Per-sample IoU (Fake class)\n",
    "        valid_pred = preds[i][valid_mask[i]]\n",
    "        valid_label = labels[i][valid_mask[i]]\n",
    "        intersection = ((valid_pred == 1) & (valid_label == 1)).sum()\n",
    "        union = ((valid_pred == 1) | (valid_label == 1)).sum()\n",
    "        if union > 0:\n",
    "            sample_ious.append(float(intersection / union))\n",
    "    \n",
    "    return {\n",
    "        # Standard metrics\n",
    "        \"mean_iou\": float(iou_metrics[\"mean_iou\"]),\n",
    "        \"accuracy\": float(iou_metrics[\"mean_accuracy\"]),\n",
    "        \"fake_iou\": float(iou_metrics[\"per_category_iou\"][1]) if len(iou_metrics[\"per_category_iou\"]) > 1 else 0.0,\n",
    "        \"bg_iou\": float(iou_metrics[\"per_category_iou\"][0]),\n",
    "        \n",
    "        # Confidence metrics\n",
    "        \"avg_pixel_confidence\": avg_pixel_confidence,\n",
    "        \"avg_boundary_confidence\": float(np.mean(boundary_confidences)) if boundary_confidences else 0.0,\n",
    "        \"avg_sample_iou\": float(np.mean(sample_ious)) if sample_ious else 0.0,\n",
    "        \n",
    "        # Boundary analysis\n",
    "        \"boundary_iou\": float(np.mean(boundary_ious)) if boundary_ious else 0.0,\n",
    "        \"interior_iou\": float(np.mean(interior_ious)) if interior_ious else 0.0,\n",
    "    }\n",
    "\n",
    "print(\"Enhanced Metrik fonksiyonu hazÄ±r:\")\n",
    "print(\"  - Standard: mean_iou, fake_iou, bg_iou, accuracy\")\n",
    "print(\"  - Confidence: pixel, boundary, sample-level\")\n",
    "print(\"  - Boundary Analysis: boundary_iou vs interior_iou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4544b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HUCRE 6.5: CUSTOM TRAINER VE METRICS TRACKER CALLBACK\n",
    "# =============================================================================\n",
    "from transformers import TrainerCallback, Trainer\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CUSTOM TRAINER: Custom Loss Function desteÄŸi\n",
    "# -----------------------------------------------------------------------------\n",
    "class SegformerTrainerWithCustomLoss(Trainer):\n",
    "    \"\"\"\n",
    "    HuggingFace Trainer with custom loss function support\n",
    "    Allows using DiceFocalLoss instead of default CrossEntropy\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, custom_loss_fn=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.custom_loss_fn = custom_loss_fn\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Upsample logits to match label size\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits, size=labels.shape[-2:],\n",
    "            mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        \n",
    "        # Use custom loss if provided\n",
    "        if self.custom_loss_fn is not None:\n",
    "            loss = self.custom_loss_fn(upsampled_logits, labels)\n",
    "        else:\n",
    "            # Default CrossEntropy\n",
    "            loss = nn.functional.cross_entropy(\n",
    "                upsampled_logits.view(-1, CONFIG['num_classes']),\n",
    "                labels.view(-1).long(),\n",
    "                ignore_index=255\n",
    "            )\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# METRICS TRACKER CALLBACK: Progress bar + History tracking + CSV export\n",
    "# -----------------------------------------------------------------------------\n",
    "class MetricsTrackerCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    Comprehensive callback for:\n",
    "    1. Real-time progress bar with IoU metrics\n",
    "    2. History tracking (all metrics per epoch)\n",
    "    3. CSV export after each epoch\n",
    "    4. Best model tracking\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, viz_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.viz_dir = viz_dir\n",
    "        self.models_dir = models_dir  # Model kaydetme iÃ§in (best_model ve last_model)\n",
    "        \n",
    "        # History tracking\n",
    "        self.history = {\n",
    "            'epoch': [],\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_mean_iou': [],\n",
    "            'val_fake_iou': [],\n",
    "            'val_bg_iou': [],\n",
    "            'val_accuracy': [],\n",
    "            'val_pixel_confidence': [],\n",
    "            'val_boundary_confidence': [],\n",
    "            'val_sample_iou': [],\n",
    "            'val_boundary_iou': [],\n",
    "            'val_interior_iou': [],\n",
    "            'learning_rate': []\n",
    "        }\n",
    "        \n",
    "        # Progress tracking\n",
    "        self.train_pbar = None\n",
    "        self.current_epoch = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        # Best model tracking\n",
    "        self.best_fake_iou = 0.0\n",
    "        self.best_epoch = 0\n",
    "    \n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"EGITIM BASLIYOR\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"  Total epochs: {int(args.num_train_epochs)}\")\n",
    "        print(f\"  Total steps: {state.max_steps}\")\n",
    "        print(f\"  Loss type: {CONFIG['loss_type']}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
    "        self.current_epoch = int(state.epoch) if state.epoch else 0\n",
    "        self.epoch_start_time = time.time()\n",
    "        \n",
    "        print(f\"\\n{'â”€'*70}\")\n",
    "        print(f\"EPOCH {self.current_epoch + 1}/{int(args.num_train_epochs)}\")\n",
    "        print(f\"{'â”€'*70}\")\n",
    "        \n",
    "        # Calculate steps per epoch\n",
    "        steps_per_epoch = max(1, state.max_steps // int(args.num_train_epochs))\n",
    "        \n",
    "        # Create progress bar\n",
    "        self.train_pbar = tqdm(\n",
    "            total=steps_per_epoch,\n",
    "            desc=f\"Training\",\n",
    "            position=0,\n",
    "            leave=True,\n",
    "            ncols=100\n",
    "        )\n",
    "    \n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        if self.train_pbar:\n",
    "            self.train_pbar.update(1)\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if self.train_pbar and logs:\n",
    "            # Update progress bar with current metrics\n",
    "            postfix = {}\n",
    "            \n",
    "            if 'loss' in logs:\n",
    "                postfix['loss'] = f\"{logs['loss']:.4f}\"\n",
    "            \n",
    "            if 'learning_rate' in logs:\n",
    "                postfix['lr'] = f\"{logs['learning_rate']:.2e}\"\n",
    "            \n",
    "            # Show eval metrics if available\n",
    "            if 'eval_mean_iou' in logs:\n",
    "                postfix['mIoU'] = f\"{logs['eval_mean_iou']:.4f}\"\n",
    "            if 'eval_fake_iou' in logs:\n",
    "                postfix['fIoU'] = f\"{logs['eval_fake_iou']:.4f}\"\n",
    "            \n",
    "            self.train_pbar.set_postfix(postfix)\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        \"\"\"Called after each evaluation\"\"\"\n",
    "        if self.train_pbar:\n",
    "            self.train_pbar.close()\n",
    "            self.train_pbar = None\n",
    "        \n",
    "        if metrics:\n",
    "            epoch_num = self.current_epoch + 1\n",
    "            epoch_time = time.time() - self.epoch_start_time if self.epoch_start_time else 0\n",
    "            \n",
    "            # Record history\n",
    "            self.history['epoch'].append(epoch_num)\n",
    "            self.history['train_loss'].append(metrics.get('train_loss', 0))\n",
    "            self.history['val_loss'].append(metrics.get('eval_loss', 0))\n",
    "            self.history['val_mean_iou'].append(metrics.get('eval_mean_iou', 0))\n",
    "            self.history['val_fake_iou'].append(metrics.get('eval_fake_iou', 0))\n",
    "            self.history['val_bg_iou'].append(metrics.get('eval_bg_iou', 0))\n",
    "            self.history['val_accuracy'].append(metrics.get('eval_accuracy', 0))\n",
    "            self.history['val_pixel_confidence'].append(metrics.get('eval_avg_pixel_confidence', 0))\n",
    "            self.history['val_boundary_confidence'].append(metrics.get('eval_avg_boundary_confidence', 0))\n",
    "            self.history['val_sample_iou'].append(metrics.get('eval_avg_sample_iou', 0))\n",
    "            self.history['val_boundary_iou'].append(metrics.get('eval_boundary_iou', 0))\n",
    "            self.history['val_interior_iou'].append(metrics.get('eval_interior_iou', 0))\n",
    "            self.history['learning_rate'].append(state.log_history[-1].get('learning_rate', 0) if state.log_history else 0)\n",
    "            \n",
    "            # Track best model\n",
    "            current_fake_iou = metrics.get('eval_fake_iou', 0)\n",
    "            is_best = current_fake_iou > self.best_fake_iou\n",
    "            if is_best:\n",
    "                self.best_fake_iou = current_fake_iou\n",
    "                self.best_epoch = epoch_num\n",
    "                self._is_best_epoch = True  # Model kaydetme iÃ§in flag\n",
    "            else:\n",
    "                self._is_best_epoch = False\n",
    "\n",
    "            # Save models: best_model and last_model\n",
    "            if self.models_dir:\n",
    "                trainer = kwargs.get('trainer', None)\n",
    "                if trainer is not None:\n",
    "                    # Her epoch sonunda last_model'i kaydet\n",
    "                    last_model_path = os.path.join(self.models_dir, \"last_model\")\n",
    "                    trainer.save_model(last_model_path)\n",
    "                    # Processor'Ä± kaydet (global processor deÄŸiÅŸkeninden)\n",
    "                    try:\n",
    "                        if 'processor' in globals():\n",
    "                            processor.save_pretrained(last_model_path)\n",
    "                    except Exception as e:\n",
    "                        print(f\"  âš ï¸  Processor kaydedilemedi: {e}\")\n",
    "                    \n",
    "                    # En iyi model ise best_model'i gÃ¼ncelle\n",
    "                    if is_best:\n",
    "                        best_model_path = os.path.join(self.models_dir, \"best_model\")\n",
    "                        trainer.save_model(best_model_path)\n",
    "                        try:\n",
    "                            if 'processor' in globals():\n",
    "                                processor.save_pretrained(best_model_path)\n",
    "                        except Exception as e:\n",
    "                            print(f\"  âš ï¸  Processor kaydedilemedi: {e}\")\n",
    "                        print(f\"  ğŸ’¾ Best model kaydedildi: {best_model_path} (Fake IoU: {current_fake_iou:.4f})\")\n",
    "                    else:\n",
    "                        print(f\"  ğŸ’¾ Last model kaydedildi: {last_model_path} (Epoch {epoch_num})\")\n",
    "            \n",
    "            # Print epoch summary\n",
    "            print(f\"\\n  Epoch {epoch_num} Summary ({epoch_time:.1f}s):\")\n",
    "            print(f\"  {'â”€'*50}\")\n",
    "            print(f\"  Train Loss:        {metrics.get('train_loss', 0):.4f}\")\n",
    "            print(f\"  Val Loss:          {metrics.get('eval_loss', 0):.4f}\")\n",
    "            print(f\"  Val Mean IoU:      {metrics.get('eval_mean_iou', 0):.4f}\")\n",
    "            print(f\"  Val Fake IoU:      {metrics.get('eval_fake_iou', 0):.4f} {'NEW BEST!' if is_best else ''}\")\n",
    "            print(f\"  Val BG IoU:        {metrics.get('eval_bg_iou', 0):.4f}\")\n",
    "            print(f\"  Val Accuracy:      {metrics.get('eval_accuracy', 0):.4f}\")\n",
    "            print(f\"  {'â”€'*50}\")\n",
    "            print(f\"  Pixel Confidence:  {metrics.get('eval_avg_pixel_confidence', 0):.4f}\")\n",
    "            print(f\"  Boundary Conf:     {metrics.get('eval_avg_boundary_confidence', 0):.4f}\")\n",
    "            print(f\"  Boundary IoU:      {metrics.get('eval_boundary_iou', 0):.4f}\")\n",
    "            print(f\"  Interior IoU:      {metrics.get('eval_interior_iou', 0):.4f}\")\n",
    "            \n",
    "            # Save history to CSV after each epoch\n",
    "            self._save_history_csv()\n",
    "    \n",
    "    def _save_history_csv(self):\n",
    "        \"\"\"Export training history to CSV\"\"\"\n",
    "        df = pd.DataFrame(self.history)\n",
    "        csv_path = os.path.join(self.data_dir, 'training_history.csv')\n",
    "        df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"EGITIM TAMAMLANDI\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"  Best Fake IoU: {self.best_fake_iou:.4f} (Epoch {self.best_epoch})\")\n",
    "        print(f\"  Total Epochs:  {len(self.history['epoch'])}\")\n",
    "        print(f\"  History saved: {os.path.join(self.data_dir, 'training_history.csv')}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "print(\"Custom Trainer ve MetricsTrackerCallback hazir:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63fea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HUCRE 7: TRAINING ARGUMENTS VE TRAINER SETUP\n",
    "# =============================================================================\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. Loss Function olustur (CONFIG'e gore)\n",
    "# -----------------------------------------------------------------------------\n",
    "if CONFIG['loss_type'] == 'dice_focal':\n",
    "    focal_alpha = torch.tensor(CONFIG['focal_alpha']).float()\n",
    "    custom_loss = DiceFocalLoss(\n",
    "        dice_weight=CONFIG['dice_weight'],\n",
    "        focal_weight=CONFIG['focal_weight'],\n",
    "        focal_alpha=focal_alpha,\n",
    "        focal_gamma=CONFIG['focal_gamma'],\n",
    "        smooth=CONFIG['dice_smooth']\n",
    "    )\n",
    "    print(f\"Loss Function: DiceFocalLoss\")\n",
    "    print(f\"  Dice weight: {CONFIG['dice_weight']}, Focal weight: {CONFIG['focal_weight']}\")\n",
    "    print(f\"  Focal gamma: {CONFIG['focal_gamma']}, Alpha: {CONFIG['focal_alpha']}\")\n",
    "\n",
    "elif CONFIG['loss_type'] == 'focal':\n",
    "    focal_alpha = torch.tensor(CONFIG['focal_alpha']).float()\n",
    "    custom_loss = FocalLoss(\n",
    "        alpha=focal_alpha,\n",
    "        gamma=CONFIG['focal_gamma']\n",
    "    )\n",
    "    print(f\"Loss Function: FocalLoss\")\n",
    "    print(f\"  Gamma: {CONFIG['focal_gamma']}, Alpha: {CONFIG['focal_alpha']}\")\n",
    "\n",
    "elif CONFIG['loss_type'] == 'dice':\n",
    "    custom_loss = DiceLoss(smooth=CONFIG['dice_smooth'])\n",
    "    print(f\"Loss Function: DiceLoss\")\n",
    "\n",
    "else:  # crossentropy (default)\n",
    "    custom_loss = None\n",
    "    print(f\"Loss Function: CrossEntropy (default)\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. Training Arguments\n",
    "# -----------------------------------------------------------------------------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=CONFIG['output_dir'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    num_train_epochs=CONFIG['num_epochs'],\n",
    "    per_device_train_batch_size=CONFIG['batch_size'],\n",
    "    per_device_eval_batch_size=CONFIG['batch_size'],\n",
    "    gradient_accumulation_steps=CONFIG['gradient_accumulation'],\n",
    "    weight_decay=CONFIG['weight_decay'],\n",
    "\n",
    "    # Checkpoint strategy\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",  # eval_strategy yerine evaluation_strategy\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"fake_iou\",\n",
    "    greater_is_better=True,\n",
    "\n",
    "    # GPU Optimizations (RTX 5080)\n",
    "    fp16=True,\n",
    "    tf32=True,\n",
    "    \n",
    "    # Windows compatibility\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=True,\n",
    "    \n",
    "    # Logging\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",\n",
    "    \n",
    "    # Misc\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. Callback olustur\n",
    "# -----------------------------------------------------------------------------\n",
    "metrics_callback = MetricsTrackerCallback(\n",
    "    data_dir=CONFIG['data_dir'],\n",
    "    viz_dir=CONFIG['viz_dir'],\n",
    "    models_dir=CONFIG['models_dir']  # Model kaydetme iÃ§in (best_model ve last_model)\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. Trainer olustur\n",
    "# -----------------------------------------------------------------------------\n",
    "trainer = SegformerTrainerWithCustomLoss(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics_with_confidence,\n",
    "    callbacks=[metrics_callback],\n",
    "    custom_loss_fn=custom_loss\n",
    ")\n",
    "\n",
    "print(f\"\\nTrainer hazir:\")\n",
    "print(f\"  Custom Loss: {CONFIG['loss_type']}\")\n",
    "print(f\"  Metrics Callback: Aktif\")\n",
    "print(f\"  Output: {CONFIG['output_dir']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6591e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HUCRE 7.5: VISUALIZATION FUNCTIONS (Tam Paket)\n",
    "# =============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Style setup\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. TRAINING CURVES (3 panel)\n",
    "# -----------------------------------------------------------------------------\n",
    "def plot_training_curves(history, save_path):\n",
    "    \"\"\"\n",
    "    Plot training curves: Loss, IoU, Learning Rate\n",
    "    \"\"\"\n",
    "    epochs = history['epoch']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Panel 1: Loss\n",
    "    axes[0].plot(epochs, history['train_loss'], 'b-o', label='Train Loss', linewidth=2, markersize=6)\n",
    "    axes[0].plot(epochs, history['val_loss'], 'r-s', label='Val Loss', linewidth=2, markersize=6)\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend(fontsize=10)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Panel 2: IoU Metrics\n",
    "    axes[1].plot(epochs, history['val_mean_iou'], 'g-o', label='Mean IoU', linewidth=2, markersize=6)\n",
    "    axes[1].plot(epochs, history['val_fake_iou'], color='orange', marker='s', label='Fake IoU', linewidth=2, markersize=6)\n",
    "    axes[1].plot(epochs, history['val_bg_iou'], color='purple', marker='^', label='BG IoU', linewidth=2, markersize=6)\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('IoU Score', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('Validation IoU Metrics', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_ylim([0, 1])\n",
    "    \n",
    "    # Panel 3: Learning Rate\n",
    "    axes[2].plot(epochs, history['learning_rate'], 'purple', marker='o', linewidth=2, markersize=6)\n",
    "    axes[2].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "    axes[2].set_ylabel('Learning Rate', fontsize=12, fontweight='bold')\n",
    "    axes[2].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "    axes[2].set_yscale('log')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Training curves kaydedildi: {save_path}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. COMPREHENSIVE ANALYSIS DASHBOARD (8 panel)\n",
    "# -----------------------------------------------------------------------------\n",
    "def plot_comprehensive_analysis(history, save_path, version):\n",
    "    \"\"\"\n",
    "    8-panel comprehensive dashboard\n",
    "    \"\"\"\n",
    "    epochs = history['epoch']\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n",
    "    \n",
    "    # Panel 1: Loss Curves\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.plot(epochs, history['train_loss'], 'b-o', label='Train', linewidth=2, markersize=4)\n",
    "    ax1.plot(epochs, history['val_loss'], 'r-s', label='Val', linewidth=2, markersize=4)\n",
    "    ax1.set_title('Loss Curves', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Panel 2: IoU Metrics\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(epochs, history['val_mean_iou'], 'g-o', label='Mean IoU', linewidth=2)\n",
    "    ax2.plot(epochs, history['val_fake_iou'], color='orange', marker='s', label='Fake IoU', linewidth=2)\n",
    "    ax2.set_title('IoU Performance', fontsize=12, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('IoU')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim([0, 1])\n",
    "    \n",
    "    # Panel 3: Learning Rate\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.plot(epochs, history['learning_rate'], 'purple', marker='o', linewidth=2)\n",
    "    ax3.set_title('Learning Rate', fontsize=12, fontweight='bold')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('LR')\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Panel 4: Loss Gap (Overfitting indicator)\n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    loss_gap = [v - t for t, v in zip(history['train_loss'], history['val_loss'])]\n",
    "    ax4.plot(epochs, loss_gap, 'darkred', marker='o', linewidth=2)\n",
    "    ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    ax4.set_title('Loss Gap (Val - Train)', fontsize=12, fontweight='bold')\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.set_ylabel('Gap')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.fill_between(epochs, 0, loss_gap, alpha=0.3, color='red')\n",
    "    \n",
    "    # Panel 5: Confidence Metrics\n",
    "    ax5 = fig.add_subplot(gs[1, 1])\n",
    "    ax5.plot(epochs, history['val_pixel_confidence'], 'cyan', marker='o', label='Pixel Conf', linewidth=2)\n",
    "    ax5.plot(epochs, history['val_boundary_confidence'], 'magenta', marker='s', label='Boundary Conf', linewidth=2)\n",
    "    ax5.set_title('Confidence Metrics', fontsize=12, fontweight='bold')\n",
    "    ax5.set_xlabel('Epoch')\n",
    "    ax5.set_ylabel('Confidence')\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    ax5.set_ylim([0, 1])\n",
    "    \n",
    "    # Panel 6: Boundary vs Interior IoU\n",
    "    ax6 = fig.add_subplot(gs[1, 2])\n",
    "    ax6.plot(epochs, history['val_boundary_iou'], 'darkblue', marker='o', label='Boundary', linewidth=2)\n",
    "    ax6.plot(epochs, history['val_interior_iou'], 'darkgreen', marker='s', label='Interior', linewidth=2)\n",
    "    ax6.set_title('Boundary vs Interior IoU', fontsize=12, fontweight='bold')\n",
    "    ax6.set_xlabel('Epoch')\n",
    "    ax6.set_ylabel('IoU')\n",
    "    ax6.legend()\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    ax6.set_ylim([0, 1])\n",
    "    \n",
    "    # Panel 7: Metrics Table\n",
    "    ax7 = fig.add_subplot(gs[2, :])\n",
    "    ax7.axis('off')\n",
    "    \n",
    "    table_data = []\n",
    "    for i, epoch in enumerate(epochs):\n",
    "        row = [\n",
    "            f\"{epoch}\",\n",
    "            f\"{history['train_loss'][i]:.4f}\",\n",
    "            f\"{history['val_loss'][i]:.4f}\",\n",
    "            f\"{history['val_mean_iou'][i]:.4f}\",\n",
    "            f\"{history['val_fake_iou'][i]:.4f}\",\n",
    "            f\"{history['val_accuracy'][i]:.4f}\",\n",
    "            f\"{history['learning_rate'][i]:.2e}\"\n",
    "        ]\n",
    "        table_data.append(row)\n",
    "    \n",
    "    table = ax7.table(\n",
    "        cellText=table_data,\n",
    "        colLabels=['Epoch', 'Train Loss', 'Val Loss', 'Mean IoU', 'Fake IoU', 'Accuracy', 'LR'],\n",
    "        cellLoc='center',\n",
    "        loc='center',\n",
    "        bbox=[0, 0, 1, 1]\n",
    "    )\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 1.5)\n",
    "    \n",
    "    # Header style\n",
    "    for i in range(7):\n",
    "        table[(0, i)].set_facecolor('#4CAF50')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    # Highlight best epoch\n",
    "    if history['val_fake_iou']:\n",
    "        best_idx = history['val_fake_iou'].index(max(history['val_fake_iou']))\n",
    "        for i in range(7):\n",
    "            table[(best_idx + 1, i)].set_facecolor('#FFD700')\n",
    "    \n",
    "    fig.suptitle(f'Comprehensive Training Analysis - Version {version}', fontsize=16, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Comprehensive analysis kaydedildi: {save_path}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. SEGMENTATION SAMPLES GRID\n",
    "# -----------------------------------------------------------------------------\n",
    "def plot_segmentation_samples(model, val_dataset, save_path, num_samples=8, device='cuda'):\n",
    "    \"\"\"\n",
    "    Visualize segmentation predictions in grid\n",
    "    Shows: Original | Ground Truth | Prediction | Overlay\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Randomly select samples\n",
    "    indices = np.random.choice(len(val_dataset), size=min(num_samples, len(val_dataset)), replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4*num_samples))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, sample_idx in enumerate(indices):\n",
    "            sample = val_dataset[int(sample_idx)]\n",
    "            \n",
    "            pixel_values = sample['pixel_values'].unsqueeze(0).to(device)\n",
    "            gt_mask = sample['labels'].cpu().numpy()\n",
    "            \n",
    "            # Predict\n",
    "            outputs = model(pixel_values=pixel_values)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # Upsample and get prediction\n",
    "            upsampled = torch.nn.functional.interpolate(\n",
    "                logits, size=gt_mask.shape,\n",
    "                mode='bilinear', align_corners=False\n",
    "            )\n",
    "            pred_mask = upsampled.argmax(dim=1).squeeze().cpu().numpy()\n",
    "            \n",
    "            # Denormalize image\n",
    "            img_array = pixel_values.squeeze().cpu().permute(1, 2, 0).numpy()\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            img_array = img_array * std + mean\n",
    "            img_array = np.clip(img_array, 0, 1)\n",
    "            \n",
    "            # Column 1: Original Image\n",
    "            axes[idx, 0].imshow(img_array)\n",
    "            axes[idx, 0].set_title('Original', fontweight='bold')\n",
    "            axes[idx, 0].axis('off')\n",
    "            \n",
    "            # Column 2: Ground Truth\n",
    "            axes[idx, 1].imshow(gt_mask, cmap='RdYlBu', vmin=0, vmax=1)\n",
    "            axes[idx, 1].set_title('Ground Truth', fontweight='bold')\n",
    "            axes[idx, 1].axis('off')\n",
    "            \n",
    "            # Column 3: Prediction\n",
    "            axes[idx, 2].imshow(pred_mask, cmap='RdYlBu', vmin=0, vmax=1)\n",
    "            axes[idx, 2].set_title('Prediction', fontweight='bold')\n",
    "            axes[idx, 2].axis('off')\n",
    "            \n",
    "            # Column 4: Overlay\n",
    "            overlay = img_array.copy()\n",
    "            # Red for fake regions (prediction)\n",
    "            fake_mask = pred_mask == 1\n",
    "            overlay[fake_mask, 0] = np.clip(overlay[fake_mask, 0] + 0.5, 0, 1)\n",
    "            overlay[fake_mask, 1] = overlay[fake_mask, 1] * 0.5\n",
    "            overlay[fake_mask, 2] = overlay[fake_mask, 2] * 0.5\n",
    "            axes[idx, 3].imshow(overlay)\n",
    "            axes[idx, 3].set_title('Overlay (Red=Fake)', fontweight='bold')\n",
    "            axes[idx, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Segmentation samples kaydedildi: {save_path}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. IoU DISTRIBUTION\n",
    "# -----------------------------------------------------------------------------\n",
    "def plot_iou_distribution(history, save_path):\n",
    "    \"\"\"IoU distribution over epochs\"\"\"\n",
    "    epochs = history['epoch']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Bar chart: IoU comparison\n",
    "    x = np.arange(len(epochs))\n",
    "    width = 0.25\n",
    "    \n",
    "    axes[0].bar(x - width, history['val_fake_iou'], width, label='Fake IoU', color='orange', alpha=0.8)\n",
    "    axes[0].bar(x, history['val_bg_iou'], width, label='BG IoU', color='blue', alpha=0.8)\n",
    "    axes[0].bar(x + width, history['val_mean_iou'], width, label='Mean IoU', color='green', alpha=0.8)\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('IoU Score', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('IoU Comparison by Epoch', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(epochs)\n",
    "    axes[0].legend()\n",
    "    axes[0].set_ylim([0, 1])\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Box plot: Boundary vs Interior\n",
    "    boundary_data = history['val_boundary_iou']\n",
    "    interior_data = history['val_interior_iou']\n",
    "    \n",
    "    axes[1].boxplot([boundary_data, interior_data], labels=['Boundary IoU', 'Interior IoU'])\n",
    "    axes[1].set_ylabel('IoU Score', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('Boundary vs Interior IoU Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"IoU distribution kaydedildi: {save_path}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. CONFIDENCE DISTRIBUTION\n",
    "# -----------------------------------------------------------------------------\n",
    "def plot_confidence_analysis(history, save_path):\n",
    "    \"\"\"Confidence analysis plot\"\"\"\n",
    "    epochs = history['epoch']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Line plot: Confidence over epochs\n",
    "    axes[0].plot(epochs, history['val_pixel_confidence'], 'b-o', label='Pixel Confidence', linewidth=2)\n",
    "    axes[0].plot(epochs, history['val_boundary_confidence'], 'r-s', label='Boundary Confidence', linewidth=2)\n",
    "    axes[0].fill_between(epochs, history['val_pixel_confidence'], history['val_boundary_confidence'], alpha=0.3)\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('Confidence', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('Confidence Over Training', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].set_ylim([0, 1])\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Scatter: Confidence vs IoU\n",
    "    axes[1].scatter(history['val_pixel_confidence'], history['val_fake_iou'], \n",
    "                   c=epochs, cmap='viridis', s=100, alpha=0.8)\n",
    "    axes[1].set_xlabel('Pixel Confidence', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Fake IoU', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('Confidence vs IoU (Color=Epoch)', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    cbar = plt.colorbar(axes[1].collections[0], ax=axes[1])\n",
    "    cbar.set_label('Epoch')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Confidence analysis kaydedildi: {save_path}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6. ROC/PR CURVES (Segmentation iÃ§in threshold-based)\n",
    "# -----------------------------------------------------------------------------\n",
    "def plot_roc_pr_curves(all_labels, all_confidences, save_path):\n",
    "    \"\"\"\n",
    "    Segmentation iÃ§in threshold-based ROC/PR curves\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "    \n",
    "    # Binary classification iÃ§in: Fake class = 1\n",
    "    y_true = (np.array(all_labels) == 1).astype(int)\n",
    "    y_scores = np.array(all_confidences)\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, roc_thresholds = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # PR Curve\n",
    "    precision, recall, pr_thresholds = precision_recall_curve(y_true, y_scores)\n",
    "    ap_score = auc(recall, precision)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # ROC Curve\n",
    "    axes[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    axes[0].set_xlim([0.0, 1.0])\n",
    "    axes[0].set_ylim([0.0, 1.05])\n",
    "    axes[0].set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend(loc=\"lower right\")\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # PR Curve\n",
    "    axes[1].plot(recall, precision, color='darkblue', lw=2, label=f'PR curve (AP = {ap_score:.4f})')\n",
    "    axes[1].set_xlim([0.0, 1.0])\n",
    "    axes[1].set_ylim([0.0, 1.05])\n",
    "    axes[1].set_xlabel('Recall', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Precision', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(loc=\"lower left\")\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"ROC/PR curves kaydedildi: {save_path}\")\n",
    "    \n",
    "    # Export data\n",
    "    export_roc_pr_curve_data_csv(fpr, tpr, precision, recall, roc_thresholds, \n",
    "                                 save_path.replace('.png', '_data.csv'))\n",
    "    \n",
    "    return fpr, tpr, precision, recall, roc_auc, ap_score\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7. CONFIDENCE THRESHOLD ANALYSIS\n",
    "# -----------------------------------------------------------------------------\n",
    "def plot_confidence_threshold_analysis(all_labels, all_confidences, all_predictions, save_path):\n",
    "    \"\"\"\n",
    "    FarklÄ± threshold'larda performans analizi\n",
    "    \"\"\"\n",
    "    thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    \n",
    "    # Calculate metrics for each threshold\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        threshold_preds = (all_confidences >= threshold).astype(int)\n",
    "        cm = confusion_matrix(all_labels, threshold_preds)\n",
    "        if cm.size == 4:\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            acc = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "            prec = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            rec = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0\n",
    "        else:\n",
    "            acc = prec = rec = f1 = 0\n",
    "        \n",
    "        accuracies.append(acc)\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Metrics vs Threshold\n",
    "    axes[0].plot(thresholds, accuracies, 'b-o', label='Accuracy', linewidth=2, markersize=4)\n",
    "    axes[0].plot(thresholds, precisions, 'r-s', label='Precision', linewidth=2, markersize=4)\n",
    "    axes[0].plot(thresholds, recalls, 'g-^', label='Recall', linewidth=2, markersize=4)\n",
    "    axes[0].plot(thresholds, f1_scores, 'm-d', label='F1-Score', linewidth=2, markersize=4)\n",
    "    axes[0].set_xlabel('Confidence Threshold', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('Metric Value', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('Performance vs Confidence Threshold', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_ylim([0, 1])\n",
    "    \n",
    "    # Optimal threshold (max F1)\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    axes[0].axvline(x=optimal_threshold, color='orange', linestyle='--', linewidth=2, \n",
    "                   label=f'Optimal (F1={f1_scores[optimal_idx]:.3f})')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Precision-Recall Trade-off\n",
    "    axes[1].plot(recalls, precisions, 'b-o', linewidth=2, markersize=4)\n",
    "    axes[1].scatter([recalls[optimal_idx]], [precisions[optimal_idx]], \n",
    "                   color='red', s=200, zorder=5, label=f'Optimal (t={optimal_threshold:.2f})')\n",
    "    axes[1].set_xlabel('Recall', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Precision', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('Precision-Recall Trade-off', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_ylim([0, 1])\n",
    "    axes[1].set_xlim([0, 1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Confidence threshold analysis kaydedildi: {save_path}\")\n",
    "    print(f\"Optimal threshold: {optimal_threshold:.3f} (F1={f1_scores[optimal_idx]:.3f})\")\n",
    "    \n",
    "    return optimal_threshold, thresholds, accuracies, precisions, recalls, f1_scores\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8. CALIBRATION CURVES\n",
    "# -----------------------------------------------------------------------------\n",
    "def plot_calibration_curves(all_labels, all_confidences, save_path, n_bins=10):\n",
    "    \"\"\"\n",
    "    Model calibration analizi\n",
    "    \"\"\"\n",
    "    from sklearn.calibration import calibration_curve\n",
    "    \n",
    "    y_true = (np.array(all_labels) == 1).astype(int)\n",
    "    y_scores = np.array(all_confidences)\n",
    "    \n",
    "    # Calibration curve\n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "        y_true, y_scores, n_bins=n_bins, strategy='uniform'\n",
    "    )\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Calibration plot\n",
    "    axes[0].plot(mean_predicted_value, fraction_of_positives, \"s-\", label='Model', linewidth=2)\n",
    "    axes[0].plot([0, 1], [0, 1], \"k--\", label='Perfectly Calibrated', linewidth=2)\n",
    "    axes[0].set_xlabel('Mean Predicted Probability', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('Fraction of Positives', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('Calibration Plot', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_xlim([0, 1])\n",
    "    axes[0].set_ylim([0, 1])\n",
    "    \n",
    "    # Confidence distribution\n",
    "    axes[1].hist(y_scores, bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[1].set_xlabel('Confidence Score', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('Confidence Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Calibration curves kaydedildi: {save_path}\")\n",
    "    \n",
    "    return fraction_of_positives, mean_predicted_value\n",
    "\n",
    "\n",
    "print(\"Visualization fonksiyonlari hazir:\")\n",
    "print(\"  - plot_training_curves()\")\n",
    "print(\"  - plot_comprehensive_analysis()\")\n",
    "print(\"  - plot_segmentation_samples()\")\n",
    "print(\"  - plot_iou_distribution()\")\n",
    "print(\"  - plot_confidence_analysis()\")\n",
    "print(\"  - plot_roc_pr_curves()\")\n",
    "print(\"  - plot_confidence_threshold_analysis()\")\n",
    "print(\"  - plot_calibration_curves()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f86d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HUCRE 7.6: CSV EXPORT FUNCTIONS (SegFormer Analytics)\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "CSV export fonksiyonlarÄ± - SegFormer segmentation analizi iÃ§in\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from scipy import ndimage\n",
    "\n",
    "def export_confusion_matrix_csv(all_labels, all_predictions, save_path, class_names=['Background', 'Fake']):\n",
    "    \"\"\"\n",
    "    Confusion matrix'i CSV olarak export et (counts & percentages)\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Counts DataFrame\n",
    "    cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "    cm_df.index.name = 'True Label'\n",
    "    cm_df.columns.name = 'Predicted Label'\n",
    "    \n",
    "    # Percentages DataFrame\n",
    "    cm_norm_df = pd.DataFrame(cm_norm * 100, index=class_names, columns=class_names)\n",
    "    cm_norm_df.index.name = 'True Label'\n",
    "    cm_norm_df.columns.name = 'Predicted Label'\n",
    "    \n",
    "    # Save counts\n",
    "    counts_path = save_path.replace('.csv', '_counts.csv')\n",
    "    cm_df.to_csv(counts_path)\n",
    "    print(f\"âœ… Confusion matrix (counts) saved: {counts_path}\")\n",
    "    \n",
    "    # Save percentages\n",
    "    percent_path = save_path.replace('.csv', '_percentages.csv')\n",
    "    cm_norm_df.to_csv(percent_path)\n",
    "    print(f\"âœ… Confusion matrix (percentages) saved: {percent_path}\")\n",
    "    \n",
    "    return cm_df, cm_norm_df\n",
    "\n",
    "\n",
    "def export_classification_report_csv(all_labels, all_predictions, save_path, class_names=['Background', 'Fake']):\n",
    "    \"\"\"\n",
    "    Per-class metrics (precision, recall, f1) CSV export\n",
    "    \"\"\"\n",
    "    report_dict = classification_report(\n",
    "        all_labels, all_predictions,\n",
    "        target_names=class_names,\n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    # Per-class metrics\n",
    "    per_class_data = []\n",
    "    for class_name in class_names:\n",
    "        if class_name in report_dict:\n",
    "            per_class_data.append({\n",
    "                'class': class_name,\n",
    "                'precision': report_dict[class_name]['precision'],\n",
    "                'recall': report_dict[class_name]['recall'],\n",
    "                'f1_score': report_dict[class_name]['f1-score'],\n",
    "                'support': report_dict[class_name]['support']\n",
    "            })\n",
    "    \n",
    "    # Overall metrics\n",
    "    per_class_data.append({\n",
    "        'class': 'weighted_avg',\n",
    "        'precision': report_dict['weighted avg']['precision'],\n",
    "        'recall': report_dict['weighted avg']['recall'],\n",
    "        'f1_score': report_dict['weighted avg']['f1-score'],\n",
    "        'support': report_dict['weighted avg']['support']\n",
    "    })\n",
    "    \n",
    "    per_class_data.append({\n",
    "        'class': 'macro_avg',\n",
    "        'precision': report_dict['macro avg']['precision'],\n",
    "        'recall': report_dict['macro avg']['recall'],\n",
    "        'f1_score': report_dict['macro avg']['f1-score'],\n",
    "        'support': report_dict['macro avg']['support']\n",
    "    })\n",
    "    \n",
    "    df = pd.DataFrame(per_class_data)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"âœ… Classification report saved: {save_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def export_per_class_metrics_csv(iou_metrics, save_path):\n",
    "    \"\"\"\n",
    "    Background vs Fake IoU karÅŸÄ±laÅŸtÄ±rmasÄ±\n",
    "    \"\"\"\n",
    "    metrics_data = {\n",
    "        'metric': ['mean_iou', 'background_iou', 'fake_iou', 'accuracy'],\n",
    "        'value': [\n",
    "            iou_metrics.get('mean_iou', 0),\n",
    "            iou_metrics.get('bg_iou', 0),\n",
    "            iou_metrics.get('fake_iou', 0),\n",
    "            iou_metrics.get('accuracy', 0)\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(metrics_data)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"âœ… Per-class metrics saved: {save_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def export_confidence_statistics_csv(all_confidences, save_path):\n",
    "    \"\"\"\n",
    "    Confidence daÄŸÄ±lÄ±m istatistikleri\n",
    "    \"\"\"\n",
    "    conf_arr = np.array(all_confidences)\n",
    "    \n",
    "    stats = {\n",
    "        'statistic': ['mean', 'std', 'min', '25th_percentile', 'median', '75th_percentile', 'max'],\n",
    "        'value': [\n",
    "            float(np.mean(conf_arr)),\n",
    "            float(np.std(conf_arr)),\n",
    "            float(np.min(conf_arr)),\n",
    "            float(np.percentile(conf_arr, 25)),\n",
    "            float(np.median(conf_arr)),\n",
    "            float(np.percentile(conf_arr, 75)),\n",
    "            float(np.max(conf_arr))\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(stats)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"âœ… Confidence statistics saved: {save_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def export_roc_pr_curve_data_csv(fpr, tpr, precision, recall, thresholds, save_path):\n",
    "    \"\"\"\n",
    "    ROC/PR curve verileri CSV export\n",
    "    \"\"\"\n",
    "    # ROC data\n",
    "    roc_data = {\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'threshold': list(thresholds) + [np.nan] * (len(fpr) - len(thresholds)) if len(thresholds) < len(fpr) else thresholds\n",
    "    }\n",
    "    roc_df = pd.DataFrame(roc_data)\n",
    "    roc_path = save_path.replace('.csv', '_roc.csv')\n",
    "    roc_df.to_csv(roc_path, index=False)\n",
    "    print(f\"âœ… ROC curve data saved: {roc_path}\")\n",
    "    \n",
    "    # PR data\n",
    "    pr_data = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'threshold': list(thresholds) + [np.nan] * (len(precision) - len(thresholds)) if len(thresholds) < len(precision) else thresholds\n",
    "    }\n",
    "    pr_df = pd.DataFrame(pr_data)\n",
    "    pr_path = save_path.replace('.csv', '_pr.csv')\n",
    "    pr_df.to_csv(pr_path, index=False)\n",
    "    print(f\"âœ… PR curve data saved: {pr_path}\")\n",
    "    \n",
    "    return roc_df, pr_df\n",
    "\n",
    "\n",
    "def export_confidence_threshold_analysis_csv(all_labels, all_confidences, all_predictions, save_path, thresholds=None):\n",
    "    \"\"\"\n",
    "    FarklÄ± confidence threshold'larÄ±nda performans analizi\n",
    "    \"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "    \n",
    "    results = []\n",
    "    for threshold in thresholds:\n",
    "        # Threshold'a gÃ¶re prediction\n",
    "        threshold_preds = (all_confidences >= threshold).astype(int)\n",
    "        \n",
    "        # Metrics\n",
    "        cm = confusion_matrix(all_labels, threshold_preds)\n",
    "        if cm.size == 4:\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        else:\n",
    "            accuracy = precision = recall = f1 = 0\n",
    "        \n",
    "        results.append({\n",
    "            'threshold': threshold,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'true_positives': int(tp) if cm.size == 4 else 0,\n",
    "            'true_negatives': int(tn) if cm.size == 4 else 0,\n",
    "            'false_positives': int(fp) if cm.size == 4 else 0,\n",
    "            'false_negatives': int(fn) if cm.size == 4 else 0\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"âœ… Confidence threshold analysis saved: {save_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def export_spatial_analysis_csv(all_labels, all_predictions, all_metadata, save_path):\n",
    "    \"\"\"\n",
    "    Region size, aspect ratio analizi (metadata'dan)\n",
    "    \"\"\"\n",
    "    # Metadata'dan region bilgilerini topla\n",
    "    spatial_data = []\n",
    "    \n",
    "    for i, metadata in enumerate(all_metadata):\n",
    "        if metadata:\n",
    "            spatial_data.append({\n",
    "                'idx': i,\n",
    "                'true_label': all_labels[i],\n",
    "                'predicted_label': all_predictions[i],\n",
    "                'correct': int(all_labels[i] == all_predictions[i]),\n",
    "                'dataset': metadata.get('dataset', 'unknown'),\n",
    "                'area_ratio': metadata.get('area_ratio', None),\n",
    "                'sem_magnitude': metadata.get('sem_magnitude', 'unknown'),\n",
    "            })\n",
    "    \n",
    "    if spatial_data:\n",
    "        df = pd.DataFrame(spatial_data)\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(f\"âœ… Spatial analysis saved: {save_path}\")\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"âš ï¸ No spatial metadata available\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def export_error_analysis_csv(all_labels, all_predictions, all_confidences, all_metadata, save_path):\n",
    "    \"\"\"\n",
    "    False positive/negative detaylarÄ±\n",
    "    \"\"\"\n",
    "    error_data = []\n",
    "    \n",
    "    for i in range(len(all_labels)):\n",
    "        true_label = all_labels[i]\n",
    "        pred_label = all_predictions[i]\n",
    "        confidence = all_confidences[i]\n",
    "        metadata = all_metadata[i] if i < len(all_metadata) else {}\n",
    "        \n",
    "        if true_label != pred_label:\n",
    "            error_type = 'false_positive' if pred_label == 1 and true_label == 0 else 'false_negative'\n",
    "            \n",
    "            error_data.append({\n",
    "                'idx': i,\n",
    "                'error_type': error_type,\n",
    "                'true_label': true_label,\n",
    "                'predicted_label': pred_label,\n",
    "                'confidence': confidence,\n",
    "                'dataset': metadata.get('dataset', 'unknown'),\n",
    "                'area_ratio': metadata.get('area_ratio', None),\n",
    "                'sem_magnitude': metadata.get('sem_magnitude', 'unknown'),\n",
    "            })\n",
    "    \n",
    "    if error_data:\n",
    "        df = pd.DataFrame(error_data)\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(f\"âœ… Error analysis saved: {save_path} ({len(error_data)} errors)\")\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"âœ… No errors found!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "print(\"âœ… CSV export fonksiyonlarÄ± hazÄ±r:\")\n",
    "print(\"  - export_confusion_matrix_csv()\")\n",
    "print(\"  - export_classification_report_csv()\")\n",
    "print(\"  - export_per_class_metrics_csv()\")\n",
    "print(\"  - export_confidence_statistics_csv()\")\n",
    "print(\"  - export_roc_pr_curve_data_csv()\")\n",
    "print(\"  - export_confidence_threshold_analysis_csv()\")\n",
    "print(\"  - export_spatial_analysis_csv()\")\n",
    "print(\"  - export_error_analysis_csv()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gjqh4t8iac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HUCRE 8: EGITIM BASLAT VE POST-TRAINING ISLEMLERI\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"EGITIM BASLATILIYOR - {CONFIG['num_epochs']} Epoch\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Model: {CONFIG['model_name']}\")\n",
    "print(f\"  Loss: {CONFIG['loss_type']}\")\n",
    "print(f\"  Output: {CONFIG['output_dir']}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# 1. EGITIM\n",
    "trainer.train()\n",
    "\n",
    "# 2. POST-TRAINING VISUALIZATIONS\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"POST-TRAINING VISUALIZATIONS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# History'yi callback'ten al\n",
    "history = metrics_callback.history\n",
    "\n",
    "# 2.1 Training Curves\n",
    "curves_path = os.path.join(CONFIG['viz_dir'], 'training_curves.png')\n",
    "plot_training_curves(history, curves_path)\n",
    "\n",
    "# 2.2 Comprehensive Analysis Dashboard\n",
    "analysis_path = os.path.join(CONFIG['viz_dir'], 'comprehensive_training_analysis.png')\n",
    "plot_comprehensive_analysis(history, analysis_path, CONFIG['version'])\n",
    "\n",
    "# 2.3 Segmentation Samples\n",
    "samples_path = os.path.join(CONFIG['viz_dir'], 'segmentation_samples.png')\n",
    "plot_segmentation_samples(model, val_dataset, samples_path, num_samples=8, device=device)\n",
    "\n",
    "# 2.4 IoU Distribution\n",
    "iou_dist_path = os.path.join(CONFIG['viz_dir'], 'iou_distribution.png')\n",
    "plot_iou_distribution(history, iou_dist_path)\n",
    "\n",
    "# 2.5 Confidence Analysis\n",
    "conf_path = os.path.join(CONFIG['viz_dir'], 'confidence_analysis.png')\n",
    "plot_confidence_analysis(history, conf_path)\n",
    "\n",
    "# 3. MODEL KAYDET\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL KAYDEDILIYOR\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "final_model_path = os.path.join(CONFIG['models_dir'], \"final_best_model\")\n",
    "trainer.save_model(final_model_path)\n",
    "processor.save_pretrained(final_model_path)\n",
    "\n",
    "print(f\"  Model: {final_model_path}\")\n",
    "print(f\"  History: {os.path.join(CONFIG['data_dir'], 'training_history.csv')}\")\n",
    "print(f\"  Gorseller: {CONFIG['viz_dir']}\")\n",
    "\n",
    "# 4. OZET RAPOR\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"EGITIM TAMAMLANDI - Version {CONFIG['version']}\")\n",
    "print(\"=\"*70)\n",
    "print(f\"  Best Fake IoU:     {metrics_callback.best_fake_iou:.4f}\")\n",
    "print(f\"  Best Epoch:        {metrics_callback.best_epoch}\")\n",
    "print(f\"  Total Epochs:      {len(history['epoch'])}\")\n",
    "print(f\"  Final Mean IoU:    {history['val_mean_iou'][-1]:.4f}\")\n",
    "print(f\"  Final Accuracy:    {history['val_accuracy'][-1]:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf984ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HUCRE 9: EGITIM OZETI VE KAYIT KONTROLU\n",
    "# =============================================================================\n",
    "# Bu hucre, egitim tamamlandiktan sonra ozet bilgi gosterir\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EGITIM TAMAMLANDI - DOSYA KONTROLU\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# CSV kontrolu\n",
    "csv_path = os.path.join(CONFIG['data_dir'], 'training_history.csv')\n",
    "if os.path.exists(csv_path):\n",
    "    history_df = pd.read_csv(csv_path)\n",
    "    print(f\"\\nTraining History ({len(history_df)} epoch):\")\n",
    "    print(history_df[['epoch', 'val_mean_iou', 'val_fake_iou', 'val_accuracy']].to_string(index=False))\n",
    "else:\n",
    "    print(\"Henuz egitim yapilmadi!\")\n",
    "\n",
    "# Gorsel kontrolu\n",
    "print(f\"\\nGorseller ({CONFIG['viz_dir']}):\")\n",
    "for f in os.listdir(CONFIG['viz_dir']) if os.path.exists(CONFIG['viz_dir']) else []:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "# Model kontrolu\n",
    "print(f\"\\nModeller ({CONFIG['models_dir']}):\")\n",
    "for f in os.listdir(CONFIG['models_dir']) if os.path.exists(CONFIG['models_dir']) else []:\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc3fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HUCRE 10.5: VALIDATION SET CSV EXPORTS & ADVANCED VISUALIZATIONS\n",
    "# =============================================================================\n",
    "# Bu hÃ¼cre validation set analizinden sonra CSV export'larÄ± ve geliÅŸmiÅŸ gÃ¶rselleÅŸtirmeler oluÅŸturur\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VALIDATION SET CSV EXPORTS & ADVANCED VISUALIZATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ã–nce validation set'i tekrar deÄŸerlendir (eÄŸer yukarÄ±daki hÃ¼cre Ã§alÄ±ÅŸtÄ±rÄ±lmadÄ±ysa)\n",
    "if 'all_preds' not in locals() or 'all_labels' not in locals():\n",
    "    print(\"âš ï¸ Validation set analizi yapÄ±lmamÄ±ÅŸ. Ã–nce HUCRE 10'u Ã§alÄ±ÅŸtÄ±rÄ±n.\")\n",
    "    print(\"   Validation set'i deÄŸerlendirmek iÃ§in metadata ve confidence toplama eklenmiÅŸ versiyonu kullanÄ±n.\")\n",
    "else:\n",
    "    # 1. Confusion Matrix\n",
    "    cm_csv_path = os.path.join(CONFIG['data_dir'], 'confusion_matrix.csv')\n",
    "    export_confusion_matrix_csv(all_labels, all_preds, cm_csv_path)\n",
    "    \n",
    "    # 2. Classification Report\n",
    "    class_report_path = os.path.join(CONFIG['data_dir'], 'classification_report.csv')\n",
    "    export_classification_report_csv(all_labels, all_preds, class_report_path)\n",
    "    \n",
    "    # 3. Per-class Metrics\n",
    "    if 'iou_fake' in locals() and 'iou_bg' in locals() and 'mean_iou' in locals() and 'accuracy' in locals():\n",
    "        iou_metrics = {\n",
    "            'mean_iou': mean_iou,\n",
    "            'bg_iou': iou_bg,\n",
    "            'fake_iou': iou_fake,\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "        per_class_path = os.path.join(CONFIG['data_dir'], 'per_class_metrics.csv')\n",
    "        export_per_class_metrics_csv(iou_metrics, per_class_path)\n",
    "    \n",
    "    # 4. Confidence Statistics (if available)\n",
    "    if 'all_confidences' in locals() and len(all_confidences) > 0:\n",
    "        conf_stats_path = os.path.join(CONFIG['data_dir'], 'confidence_statistics.csv')\n",
    "        export_confidence_statistics_csv(all_confidences, conf_stats_path)\n",
    "        \n",
    "        # 5. Confidence Threshold Analysis\n",
    "        threshold_path = os.path.join(CONFIG['data_dir'], 'confidence_threshold_analysis.csv')\n",
    "        export_confidence_threshold_analysis_csv(all_labels, all_confidences, all_preds, threshold_path)\n",
    "    \n",
    "    # 6. Error Analysis (if metadata available)\n",
    "    if 'metadata_list' in locals() and len(metadata_list) > 0:\n",
    "        error_analysis_path = os.path.join(CONFIG['data_dir'], 'error_analysis.csv')\n",
    "        export_error_analysis_csv(all_labels, all_preds, all_confidences if 'all_confidences' in locals() else [], metadata_list, error_analysis_path)\n",
    "        \n",
    "        # 7. Spatial Analysis\n",
    "        spatial_path = os.path.join(CONFIG['data_dir'], 'spatial_analysis.csv')\n",
    "        export_spatial_analysis_csv(all_labels, all_preds, metadata_list, spatial_path)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # ADVANCED VISUALIZATIONS (if confidences available)\n",
    "    # =============================================================================\n",
    "    if 'all_confidences' in locals() and len(all_confidences) > 0:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ADVANCED VISUALIZATIONS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # 1. ROC/PR Curves\n",
    "        roc_pr_path = os.path.join(CONFIG['viz_dir'], 'roc_pr_curves.png')\n",
    "        plot_roc_pr_curves(all_labels, all_confidences, roc_pr_path)\n",
    "        \n",
    "        # 2. Confidence Threshold Analysis\n",
    "        threshold_path = os.path.join(CONFIG['viz_dir'], 'confidence_threshold_analysis.png')\n",
    "        plot_confidence_threshold_analysis(all_labels, all_confidences, all_preds, threshold_path)\n",
    "        \n",
    "        # 3. Calibration Curves\n",
    "        calibration_path = os.path.join(CONFIG['viz_dir'], 'calibration_curves.png')\n",
    "        plot_calibration_curves(all_labels, all_confidences, calibration_path)\n",
    "        \n",
    "        print(\"âœ… Advanced visualizations completed!\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # DATASET ANALYSIS (if metadata available)\n",
    "    # =============================================================================\n",
    "    if 'metadata_list' in locals() and len(metadata_list) > 0:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"DATASET ANALYSIS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Dataset performance\n",
    "        dataset_path = os.path.join(CONFIG['viz_dir'], 'dataset_performance.png')\n",
    "        analyze_dataset_performance(all_labels, all_preds, metadata_list, dataset_path)\n",
    "        \n",
    "        # Semantic magnitude analysis\n",
    "        magnitude_path = os.path.join(CONFIG['viz_dir'], 'semantic_magnitude_analysis.png')\n",
    "        analyze_by_sem_magnitude(all_labels, all_preds, metadata_list, magnitude_path)\n",
    "        \n",
    "        print(\"âœ… Dataset analysis completed!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ… TÃ¼m CSV export'larÄ± ve gÃ¶rselleÅŸtirmeler tamamlandÄ±!\")\n",
    "    print(f\"ğŸ“ CSV dosyalarÄ±: {CONFIG['data_dir']}\")\n",
    "    print(f\"ğŸ“Š GÃ¶rseller: {CONFIG['viz_dir']}\")\n",
    "    print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bdeb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HUCRE 10: VALIDATION SET CONFUSION MATRIX (Opsiyonel)\n",
    "# =============================================================================\n",
    "# Bu hucre egitimden sonra detayli confusion matrix analizi yapar\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(\"VALIDATION SET ANALIZI BASLIYOR...\")\n",
    "\n",
    "# Validation loader\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "model.eval()\n",
    "\n",
    "preds_list = []\n",
    "labels_list = []\n",
    "\n",
    "print(\"Validation verisi taranÄ±yor...\")\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        pixel_values = batch['pixel_values'].to(device)\n",
    "        labels = batch['labels'].cpu().numpy()\n",
    "        \n",
    "        outputs = model(pixel_values=pixel_values)\n",
    "        logits = torch.nn.functional.interpolate(\n",
    "            outputs.logits, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "        \n",
    "        # Sadece gecerli pikselleri al (255 olmayanlar)\n",
    "        valid_mask = labels != 255\n",
    "        preds_list.append(preds[valid_mask])\n",
    "        labels_list.append(labels[valid_mask])\n",
    "\n",
    "# Tek bir array yap\n",
    "all_preds = np.concatenate(preds_list)\n",
    "all_labels = np.concatenate(labels_list)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Grafik\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Raw counts\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Background', 'Fake'], yticklabels=['Background', 'Fake'])\n",
    "axes[0].set_title(\"Confusion Matrix (Raw Counts)\", fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel(\"Gercek\")\n",
    "axes[0].set_xlabel(\"Tahmin\")\n",
    "\n",
    "# Normalized\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Blues', ax=axes[1],\n",
    "            xticklabels=['Background', 'Fake'], yticklabels=['Background', 'Fake'])\n",
    "axes[1].set_title(\"Confusion Matrix (Normalized)\", fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel(\"Gercek\")\n",
    "axes[1].set_xlabel(\"Tahmin\")\n",
    "\n",
    "plt.tight_layout()\n",
    "cm_path = os.path.join(CONFIG['viz_dir'], 'confusion_matrix.png')\n",
    "plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Confusion Matrix kaydedildi: {cm_path}\")\n",
    "\n",
    "# Metrikler\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "iou_fake = tp / (tp + fp + fn)\n",
    "iou_bg = tn / (tn + fp + fn)\n",
    "mean_iou = (iou_fake + iou_bg) / 2\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VALIDATION SET FINAL SONUCLARI\")\n",
    "print(\"=\"*50)\n",
    "print(f\"  Fake IoU:       {iou_fake:.4f}\")\n",
    "print(f\"  Background IoU: {iou_bg:.4f}\")\n",
    "print(f\"  Mean IoU:       {mean_iou:.4f}\")\n",
    "print(f\"  Accuracy:       {accuracy:.4f}\")\n",
    "print(f\"  Precision:      {precision:.4f}\")\n",
    "print(f\"  Recall:         {recall:.4f}\")\n",
    "print(f\"  F1-Score:       {f1:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HUCRE 14: MODEL COMPARISON FUNCTIONS\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "FarklÄ± modellerin performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±rma fonksiyonlarÄ±\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def load_experiment_metadata(data_dir_pattern):\n",
    "    \"\"\"\n",
    "    Birden fazla experiment metadata dosyasÄ±nÄ± yÃ¼kle\n",
    "    \n",
    "    Args:\n",
    "        data_dir_pattern: Experiment klasÃ¶rlerinin pattern'i (Ã¶rn: \"eÄŸitim_sonuÃ§larÄ±/segformer_5080_final/v*\")\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with all experiments\n",
    "    \"\"\"\n",
    "    metadata_files = glob.glob(os.path.join(data_dir_pattern, \"**/experiment_metadata.csv\"), recursive=True)\n",
    "    \n",
    "    if not metadata_files:\n",
    "        print(f\"âš ï¸ No experiment metadata files found in: {data_dir_pattern}\")\n",
    "        return None\n",
    "    \n",
    "    all_experiments = []\n",
    "    for file in metadata_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            all_experiments.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error loading {file}: {e}\")\n",
    "    \n",
    "    if all_experiments:\n",
    "        combined_df = pd.concat(all_experiments, ignore_index=True)\n",
    "        print(f\"âœ… Loaded {len(combined_df)} experiments from {len(metadata_files)} files\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def compare_models(experiments_df, save_path=None):\n",
    "    \"\"\"\n",
    "    FarklÄ± modellerin performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±r\n",
    "    \n",
    "    Args:\n",
    "        experiments_df: Experiment metadata DataFrame\n",
    "        save_path: Optional path to save comparison plot\n",
    "    \"\"\"\n",
    "    if experiments_df is None or len(experiments_df) == 0:\n",
    "        print(\"âš ï¸ No experiments to compare\")\n",
    "        return None\n",
    "    \n",
    "    # Group by model variant\n",
    "    model_comparison = experiments_df.groupby('model_variant').agg({\n",
    "        'best_fake_iou': ['mean', 'std', 'max', 'min'],\n",
    "        'final_mean_iou': ['mean', 'std'],\n",
    "        'final_accuracy': ['mean', 'std'],\n",
    "        'experiment_id': 'count'\n",
    "    }).round(4)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MODEL COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    print(model_comparison)\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if save_path:\n",
    "        # Visualization\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        # 1. Best Fake IoU comparison\n",
    "        model_variants = experiments_df['model_variant'].unique()\n",
    "        best_ious = [experiments_df[experiments_df['model_variant'] == m]['best_fake_iou'].values \n",
    "                    for m in model_variants]\n",
    "        \n",
    "        axes[0, 0].boxplot(best_ious, labels=model_variants)\n",
    "        axes[0, 0].set_ylabel('Best Fake IoU', fontsize=12, fontweight='bold')\n",
    "        axes[0, 0].set_title('Best Fake IoU by Model Variant', fontsize=14, fontweight='bold')\n",
    "        axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # 2. Mean IoU comparison\n",
    "        mean_ious = [experiments_df[experiments_df['model_variant'] == m]['final_mean_iou'].values \n",
    "                    for m in model_variants]\n",
    "        axes[0, 1].boxplot(mean_ious, labels=model_variants)\n",
    "        axes[0, 1].set_ylabel('Mean IoU', fontsize=12, fontweight='bold')\n",
    "        axes[0, 1].set_title('Mean IoU by Model Variant', fontsize=14, fontweight='bold')\n",
    "        axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # 3. Accuracy comparison\n",
    "        accuracies = [experiments_df[experiments_df['model_variant'] == m]['final_accuracy'].values \n",
    "                     for m in model_variants]\n",
    "        axes[1, 0].boxplot(accuracies, labels=model_variants)\n",
    "        axes[1, 0].set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "        axes[1, 0].set_title('Accuracy by Model Variant', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # 4. Loss type comparison\n",
    "        if 'loss_type' in experiments_df.columns:\n",
    "            loss_types = experiments_df['loss_type'].unique()\n",
    "            loss_ious = [experiments_df[experiments_df['loss_type'] == lt]['best_fake_iou'].values \n",
    "                        for lt in loss_types]\n",
    "            axes[1, 1].boxplot(loss_ious, labels=loss_types)\n",
    "            axes[1, 1].set_ylabel('Best Fake IoU', fontsize=12, fontweight='bold')\n",
    "            axes[1, 1].set_title('Best Fake IoU by Loss Type', fontsize=14, fontweight='bold')\n",
    "            axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"âœ… Model comparison plot saved: {save_path}\")\n",
    "    \n",
    "    return model_comparison\n",
    "\n",
    "\n",
    "def compare_hyperparameters(experiments_df, save_path=None):\n",
    "    \"\"\"\n",
    "    FarklÄ± hyperparameter kombinasyonlarÄ±nÄ± karÅŸÄ±laÅŸtÄ±r\n",
    "    \"\"\"\n",
    "    if experiments_df is None or len(experiments_df) == 0:\n",
    "        print(\"âš ï¸ No experiments to compare\")\n",
    "        return None\n",
    "    \n",
    "    # Key hyperparameters\n",
    "    hyperparams = ['learning_rate', 'batch_size', 'loss_type', 'dice_weight', 'focal_weight']\n",
    "    available_params = [p for p in hyperparams if p in experiments_df.columns]\n",
    "    \n",
    "    if not available_params:\n",
    "        print(\"âš ï¸ No hyperparameter columns found\")\n",
    "        return None\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"HYPERPARAMETER COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for param in available_params:\n",
    "        if experiments_df[param].notna().any():\n",
    "            param_comparison = experiments_df.groupby(param).agg({\n",
    "                'best_fake_iou': ['mean', 'std', 'count'],\n",
    "                'final_mean_iou': 'mean',\n",
    "                'final_accuracy': 'mean'\n",
    "            }).round(4)\n",
    "            print(f\"\\n{param.upper()}:\")\n",
    "            print(param_comparison)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if save_path and len(available_params) > 0:\n",
    "        # Create correlation heatmap\n",
    "        numeric_cols = ['best_fake_iou', 'final_mean_iou', 'final_accuracy', \n",
    "                       'learning_rate', 'batch_size', 'dice_weight', 'focal_weight']\n",
    "        numeric_cols = [c for c in numeric_cols if c in experiments_df.columns]\n",
    "        \n",
    "        if len(numeric_cols) > 1:\n",
    "            corr_matrix = experiments_df[numeric_cols].corr()\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', \n",
    "                       center=0, square=True, ax=ax)\n",
    "            ax.set_title('Hyperparameter Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            print(f\"âœ… Hyperparameter correlation plot saved: {save_path}\")\n",
    "    \n",
    "    return experiments_df.groupby(available_params[0] if available_params else 'experiment_id').agg({\n",
    "        'best_fake_iou': 'mean',\n",
    "        'final_mean_iou': 'mean',\n",
    "        'final_accuracy': 'mean'\n",
    "    }).round(4) if available_params else None\n",
    "\n",
    "\n",
    "print(\"âœ… Model comparison fonksiyonlarÄ± hazÄ±r:\")\n",
    "print(\"  - load_experiment_metadata()\")\n",
    "print(\"  - compare_models()\")\n",
    "print(\"  - compare_hyperparameters()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HUCRE 15: DATASET ANALYSIS FUNCTIONS\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Dataset bazlÄ± performans analizi fonksiyonlarÄ±\n",
    "\"\"\"\n",
    "\n",
    "def analyze_dataset_performance(all_labels, all_predictions, all_metadata, save_path=None):\n",
    "    \"\"\"\n",
    "    FarklÄ± dataset'lerden gelen gÃ¶rsellerin performansÄ±nÄ± analiz et\n",
    "    \n",
    "    Args:\n",
    "        all_labels: True labels\n",
    "        all_predictions: Predicted labels\n",
    "        all_metadata: Metadata list (her prediction iÃ§in)\n",
    "        save_path: Optional path to save analysis plot\n",
    "    \"\"\"\n",
    "    if not all_metadata or len(all_metadata) == 0:\n",
    "        print(\"âš ï¸ No metadata available for dataset analysis\")\n",
    "        return None\n",
    "    \n",
    "    # Extract dataset information\n",
    "    dataset_data = []\n",
    "    for i, metadata in enumerate(all_metadata):\n",
    "        if metadata and 'dataset' in metadata:\n",
    "            dataset_data.append({\n",
    "                'dataset': metadata.get('dataset', 'unknown'),\n",
    "                'true_label': all_labels[i],\n",
    "                'predicted_label': all_predictions[i],\n",
    "                'correct': int(all_labels[i] == all_predictions[i]),\n",
    "                'area_ratio': metadata.get('area_ratio', None),\n",
    "                'sem_magnitude': metadata.get('sem_magnitude', 'unknown'),\n",
    "            })\n",
    "    \n",
    "    if not dataset_data:\n",
    "        print(\"âš ï¸ No dataset information found in metadata\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.DataFrame(dataset_data)\n",
    "    \n",
    "    # Dataset bazlÄ± metrikler\n",
    "    dataset_metrics = df.groupby('dataset').agg({\n",
    "        'correct': ['count', 'sum', 'mean'],\n",
    "        'true_label': lambda x: (x == 1).sum()  # Fake count\n",
    "    }).round(4)\n",
    "    dataset_metrics.columns = ['total_samples', 'correct_predictions', 'accuracy', 'fake_count']\n",
    "    dataset_metrics['error_rate'] = 1 - dataset_metrics['accuracy']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DATASET PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    print(dataset_metrics.sort_values('accuracy', ascending=False))\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if save_path:\n",
    "        # Visualization\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        \n",
    "        datasets = dataset_metrics.index.tolist()\n",
    "        \n",
    "        # 1. Accuracy by dataset\n",
    "        axes[0, 0].bar(datasets, dataset_metrics['accuracy'], color='steelblue', alpha=0.7, edgecolor='black')\n",
    "        axes[0, 0].set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "        axes[0, 0].set_title('Accuracy by Dataset', fontsize=14, fontweight='bold')\n",
    "        axes[0, 0].set_xticklabels(datasets, rotation=45, ha='right')\n",
    "        axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "        axes[0, 0].set_ylim([0, 1])\n",
    "        \n",
    "        # 2. Error rate by dataset\n",
    "        axes[0, 1].bar(datasets, dataset_metrics['error_rate'], color='coral', alpha=0.7, edgecolor='black')\n",
    "        axes[0, 1].set_ylabel('Error Rate', fontsize=12, fontweight='bold')\n",
    "        axes[0, 1].set_title('Error Rate by Dataset', fontsize=14, fontweight='bold')\n",
    "        axes[0, 1].set_xticklabels(datasets, rotation=45, ha='right')\n",
    "        axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # 3. Sample count by dataset\n",
    "        axes[1, 0].bar(datasets, dataset_metrics['total_samples'], color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "        axes[1, 0].set_ylabel('Sample Count', fontsize=12, fontweight='bold')\n",
    "        axes[1, 0].set_title('Sample Count by Dataset', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].set_xticklabels(datasets, rotation=45, ha='right')\n",
    "        axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # 4. Fake count vs Accuracy scatter\n",
    "        axes[1, 1].scatter(dataset_metrics['fake_count'], dataset_metrics['accuracy'], \n",
    "                          s=dataset_metrics['total_samples']*10, alpha=0.6, edgecolors='black')\n",
    "        for i, dataset in enumerate(datasets):\n",
    "            axes[1, 1].annotate(dataset, \n",
    "                               (dataset_metrics['fake_count'].iloc[i], \n",
    "                                dataset_metrics['accuracy'].iloc[i]),\n",
    "                               fontsize=8)\n",
    "        axes[1, 1].set_xlabel('Fake Sample Count', fontsize=12, fontweight='bold')\n",
    "        axes[1, 1].set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "        axes[1, 1].set_title('Fake Count vs Accuracy (size=sample count)', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"âœ… Dataset analysis plot saved: {save_path}\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_path = save_path.replace('.png', '.csv') if save_path else None\n",
    "    if csv_path:\n",
    "        dataset_metrics.to_csv(csv_path)\n",
    "        print(f\"âœ… Dataset metrics saved: {csv_path}\")\n",
    "    \n",
    "    return dataset_metrics\n",
    "\n",
    "\n",
    "def analyze_by_sem_magnitude(all_labels, all_predictions, all_metadata, save_path=None):\n",
    "    \"\"\"\n",
    "    Semantic magnitude'a gÃ¶re performans analizi\n",
    "    \"\"\"\n",
    "    if not all_metadata or len(all_metadata) == 0:\n",
    "        print(\"âš ï¸ No metadata available\")\n",
    "        return None\n",
    "    \n",
    "    magnitude_data = []\n",
    "    for i, metadata in enumerate(all_metadata):\n",
    "        if metadata and 'sem_magnitude' in metadata:\n",
    "            magnitude_data.append({\n",
    "                'sem_magnitude': metadata.get('sem_magnitude', 'unknown'),\n",
    "                'true_label': all_labels[i],\n",
    "                'predicted_label': all_predictions[i],\n",
    "                'correct': int(all_labels[i] == all_predictions[i]),\n",
    "            })\n",
    "    \n",
    "    if not magnitude_data:\n",
    "        print(\"âš ï¸ No semantic magnitude information found\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.DataFrame(magnitude_data)\n",
    "    magnitude_metrics = df.groupby('sem_magnitude').agg({\n",
    "        'correct': ['count', 'sum', 'mean']\n",
    "    }).round(4)\n",
    "    magnitude_metrics.columns = ['total_samples', 'correct_predictions', 'accuracy']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SEMANTIC MAGNITUDE PERFORMANCE\")\n",
    "    print(\"=\"*70)\n",
    "    print(magnitude_metrics.sort_values('accuracy', ascending=False))\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if save_path:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        magnitudes = magnitude_metrics.index.tolist()\n",
    "        ax.bar(magnitudes, magnitude_metrics['accuracy'], color='mediumpurple', alpha=0.7, edgecolor='black')\n",
    "        ax.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Semantic Magnitude', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Accuracy by Semantic Magnitude', fontsize=14, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        ax.set_ylim([0, 1])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"âœ… Semantic magnitude analysis saved: {save_path}\")\n",
    "    \n",
    "    return magnitude_metrics\n",
    "\n",
    "\n",
    "print(\"âœ… Dataset analysis fonksiyonlarÄ± hazÄ±r:\")\n",
    "print(\"  - analyze_dataset_performance()\")\n",
    "print(\"  - analyze_by_sem_magnitude()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13acf9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HUCRE 16: EXPERIMENT METADATA EXPORT (Standalone)\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Training sonrasÄ± experiment metadata export fonksiyonu\n",
    "MetricsTrackerCallback'te otomatik Ã§aÄŸrÄ±lmazsa bu fonksiyon kullanÄ±labilir\n",
    "\"\"\"\n",
    "\n",
    "import datetime\n",
    "\n",
    "def export_experiment_metadata_standalone(history, best_fake_iou, best_epoch, data_dir):\n",
    "    \"\"\"\n",
    "    Standalone experiment metadata export\n",
    "    \n",
    "    Args:\n",
    "        history: Training history dictionary\n",
    "        best_fake_iou: Best fake IoU value\n",
    "        best_epoch: Best epoch number\n",
    "        data_dir: Directory to save metadata\n",
    "    \"\"\"\n",
    "    # Get final metrics\n",
    "    final_metrics = {}\n",
    "    if history and history.get('epoch'):\n",
    "        final_metrics = {\n",
    "            'final_train_loss': history['train_loss'][-1] if history.get('train_loss') else None,\n",
    "            'final_val_loss': history['val_loss'][-1] if history.get('val_loss') else None,\n",
    "            'final_mean_iou': history['val_mean_iou'][-1] if history.get('val_mean_iou') else None,\n",
    "            'final_fake_iou': history['val_fake_iou'][-1] if history.get('val_fake_iou') else None,\n",
    "            'final_bg_iou': history['val_bg_iou'][-1] if history.get('val_bg_iou') else None,\n",
    "            'final_accuracy': history['val_accuracy'][-1] if history.get('val_accuracy') else None,\n",
    "            'best_fake_iou': best_fake_iou,\n",
    "            'best_epoch': best_epoch,\n",
    "        }\n",
    "    \n",
    "    # Create experiment metadata\n",
    "    experiment_metadata = {\n",
    "        'experiment_id': CONFIG.get('version', 'unknown'),\n",
    "        'timestamp': datetime.datetime.now().isoformat(),\n",
    "        'notebook_name': NOTEBOOK_NAME,\n",
    "        'dataset_name': CONFIG.get('dataset_name', 'unknown'),\n",
    "        'model_name': CONFIG.get('model_name', 'unknown'),\n",
    "        'model_variant': CONFIG.get('model_variant', 'unknown'),\n",
    "        'img_size': CONFIG.get('img_size', 512),\n",
    "        'num_classes': CONFIG.get('num_classes', 2),\n",
    "        'batch_size': CONFIG.get('batch_size', 8),\n",
    "        'gradient_accumulation': CONFIG.get('gradient_accumulation', 1),\n",
    "        'effective_batch_size': CONFIG.get('batch_size', 8) * CONFIG.get('gradient_accumulation', 1),\n",
    "        'num_epochs': CONFIG.get('num_epochs', 10),\n",
    "        'learning_rate': CONFIG.get('learning_rate', 0.0),\n",
    "        'weight_decay': CONFIG.get('weight_decay', 0.0),\n",
    "        'loss_type': CONFIG.get('loss_type', 'unknown'),\n",
    "        'dice_weight': CONFIG.get('dice_weight', None),\n",
    "        'focal_weight': CONFIG.get('focal_weight', None),\n",
    "        'focal_gamma': CONFIG.get('focal_gamma', None),\n",
    "        'focal_alpha': str(CONFIG.get('focal_alpha', None)),\n",
    "        'seed': CONFIG.get('seed', 42),\n",
    "        **final_metrics\n",
    "    }\n",
    "    \n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame([experiment_metadata])\n",
    "    csv_path = os.path.join(data_dir, 'experiment_metadata.csv')\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"âœ… Experiment metadata saved: {csv_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# EÄŸitim sonrasÄ± otomatik export (eÄŸer MetricsTrackerCallback'te yoksa)\n",
    "# Bu hÃ¼creyi eÄŸitim sonrasÄ± Ã§alÄ±ÅŸtÄ±rabilirsiniz:\n",
    "# export_experiment_metadata_standalone(\n",
    "#     metrics_callback.history, \n",
    "#     metrics_callback.best_fake_iou, \n",
    "#     metrics_callback.best_epoch,\n",
    "#     CONFIG['data_dir']\n",
    "# )\n",
    "\n",
    "print(\"âœ… Experiment metadata export fonksiyonu hazÄ±r:\")\n",
    "print(\"  - export_experiment_metadata_standalone()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2008f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HUCRE 17: MODEL COMPARISON USAGE EXAMPLE\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "FarklÄ± experiment'larÄ± karÅŸÄ±laÅŸtÄ±rmak iÃ§in kullanÄ±m Ã¶rneÄŸi\n",
    "\"\"\"\n",
    "\n",
    "# Ã–rnek kullanÄ±m (comment out edilmiÅŸ - gerektiÄŸinde aktif edin):\n",
    "\"\"\"\n",
    "# 1. TÃ¼m experiment metadata'larÄ±nÄ± yÃ¼kle\n",
    "base_pattern = \"eÄŸitim_sonuÃ§larÄ±/segformer_5080_final\"\n",
    "experiments_df = load_experiment_metadata(base_pattern)\n",
    "\n",
    "if experiments_df is not None:\n",
    "    # 2. Model karÅŸÄ±laÅŸtÄ±rmasÄ±\n",
    "    model_comp_path = os.path.join(CONFIG['viz_dir'], 'model_comparison.png')\n",
    "    compare_models(experiments_df, save_path=model_comp_path)\n",
    "    \n",
    "    # 3. Hyperparameter karÅŸÄ±laÅŸtÄ±rmasÄ±\n",
    "    hyperparam_path = os.path.join(CONFIG['viz_dir'], 'hyperparameter_comparison.png')\n",
    "    compare_hyperparameters(experiments_df, save_path=hyperparam_path)\n",
    "    \n",
    "    print(\"\\nâœ… Model comparison completed!\")\n",
    "else:\n",
    "    print(\"âš ï¸ No experiments found. Run multiple training sessions first.\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ… Model comparison kullanÄ±m Ã¶rneÄŸi hazÄ±r.\")\n",
    "print(\"   Birden fazla eÄŸitim sonrasÄ± yukarÄ±daki kodu aktif ederek karÅŸÄ±laÅŸtÄ±rma yapabilirsiniz.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf329e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HUCRE 11: MODEL YUKLEME VE INFERENCE ORNEGI\n",
    "# =============================================================================\n",
    "# Bu hucre, egitilmis modeli yukleyip tek gorsel uzerinde inference yapar\n",
    "# Test/production icin kullanilabilir\n",
    "\n",
    "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def load_trained_model(model_path, device='cuda'):\n",
    "    \"\"\"Egitilmis modeli ve processor'u yukle\"\"\"\n",
    "    processor = SegformerImageProcessor.from_pretrained(model_path)\n",
    "    model = SegformerForSemanticSegmentation.from_pretrained(model_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model, processor\n",
    "\n",
    "def predict_single_image(image_path, model, processor, device='cuda'):\n",
    "    \"\"\"\n",
    "    Tek bir gorsel icin segmentation tahmini yap\n",
    "    \n",
    "    Args:\n",
    "        image_path: Gorsel yolu\n",
    "        model: Yuklu SegFormer modeli\n",
    "        processor: SegFormer processor\n",
    "        device: cuda veya cpu\n",
    "    \n",
    "    Returns:\n",
    "        pred_mask: Binary tahmin maskesi (0: Background, 1: Fake)\n",
    "        confidence: Her piksel icin confidence degeri\n",
    "    \"\"\"\n",
    "    # Gorseli yukle\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Isle\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Tahmin\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Orijinal boyuta upsample\n",
    "        upsampled = torch.nn.functional.interpolate(\n",
    "            logits, size=image.size[::-1],  # (H, W)\n",
    "            mode='bilinear', align_corners=False\n",
    "        )\n",
    "        \n",
    "        # Softmax ve prediction\n",
    "        probs = torch.softmax(upsampled, dim=1)\n",
    "        pred_mask = probs.argmax(dim=1).squeeze().cpu().numpy()\n",
    "        confidence = probs.max(dim=1)[0].squeeze().cpu().numpy()\n",
    "    \n",
    "    return pred_mask, confidence, np.array(image)\n",
    "\n",
    "def visualize_prediction(image, pred_mask, confidence, save_path=None):\n",
    "    \"\"\"\n",
    "    Tahmin sonucunu gorsellestirir\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    \n",
    "    # 1. Orijinal\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # 2. Prediction Mask\n",
    "    axes[1].imshow(pred_mask, cmap='RdYlBu', vmin=0, vmax=1)\n",
    "    axes[1].set_title('Prediction (Blue=BG, Red=Fake)', fontsize=12, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # 3. Confidence Map\n",
    "    im = axes[2].imshow(confidence, cmap='viridis', vmin=0, vmax=1)\n",
    "    axes[2].set_title('Confidence Map', fontsize=12, fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "    plt.colorbar(im, ax=axes[2], fraction=0.046)\n",
    "    \n",
    "    # 4. Overlay\n",
    "    overlay = image.copy()\n",
    "    fake_mask = pred_mask == 1\n",
    "    overlay[fake_mask, 0] = np.clip(overlay[fake_mask, 0] + 80, 0, 255)\n",
    "    overlay[fake_mask, 1] = overlay[fake_mask, 1] * 0.7\n",
    "    overlay[fake_mask, 2] = overlay[fake_mask, 2] * 0.7\n",
    "    axes[3].imshow(overlay)\n",
    "    axes[3].set_title('Overlay (Red=Fake)', fontsize=12, fontweight='bold')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Istatistikler\n",
    "    fake_ratio = fake_mask.sum() / fake_mask.size * 100\n",
    "    mean_conf = confidence.mean()\n",
    "    fake_conf = confidence[fake_mask].mean() if fake_mask.sum() > 0 else 0\n",
    "    \n",
    "    print(f\"\\nTahmin Istatistikleri:\")\n",
    "    print(f\"  Fake Pixel Orani:    {fake_ratio:.2f}%\")\n",
    "    print(f\"  Ortalama Confidence: {mean_conf:.4f}\")\n",
    "    print(f\"  Fake Bolge Conf:     {fake_conf:.4f}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ORNEK KULLANIM\n",
    "# =============================================================================\n",
    "# Modeli yukle (egitim tamamlandiysa)\n",
    "model_path = os.path.join(CONFIG['models_dir'], \"final_best_model\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Egitilmis model yukleniyor...\")\n",
    "    trained_model, trained_processor = load_trained_model(model_path, device)\n",
    "    print(f\"Model yuklendi: {model_path}\")\n",
    "    \n",
    "    # Test icin rastgele bir gorsel sec\n",
    "    test_image_path = val_df.iloc[0]['image_path']\n",
    "    print(f\"\\nTest gorseli: {test_image_path}\")\n",
    "    \n",
    "    # Tahmin yap\n",
    "    pred_mask, confidence, image = predict_single_image(\n",
    "        test_image_path, trained_model, trained_processor, device\n",
    "    )\n",
    "    \n",
    "    # Gorsellestir\n",
    "    visualize_prediction(image, pred_mask, confidence)\n",
    "else:\n",
    "    print(f\"Model bulunamadi: {model_path}\")\n",
    "    print(\"Once egitimi tamamlayin (HUCRE 8).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
